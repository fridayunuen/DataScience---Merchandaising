{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consultando inventarios... \n",
      "Consultando ventas... \n",
      "Consultando clones... \n",
      "Preparando data... \n",
      "Identificando características de tiendas y productos....\n",
      "Detectando semanas faltantes... \n",
      "Porcentaje de datos interpolados: 1.259714906626395%\n"
     ]
    }
   ],
   "source": [
    "BU=input('''Selecciona la BU: BEAUTY JEW ACC CALZADO ROPA ''') \n",
    "\n",
    "#def CreateProyeccionActual(BU):\n",
    "\n",
    "div =   {'BEAUTY': \"[Division Code] = 'BEAUTY'\", \n",
    "            'JEW': \"[Division Code] IN ('W-JEW', 'M-JEW')\",\n",
    "            'ACC': \"[Division Code] IN ('W-ACC', 'M-ACC')\",\n",
    "        'CALZADO':\"[Division Code] in ('W-SHO','M-SHO')\",\n",
    "           'ROPA':\"[Division Code] in ('W-CLO','M-CLO')\"} \n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import os \n",
    "import get_data as gd\n",
    "\n",
    "today = datetime.date.today()\n",
    "carpeta_input = R'S:\\BI\\3. MERCHANDISING\\FRAMEWORK\\FRAMEWORK\\ZIMA\\BuffersBasicosV1\\input'\n",
    "carpeta_output = R'S:\\BI\\3. MERCHANDISING\\FRAMEWORK\\FRAMEWORK\\ZIMA\\BuffersBasicosV1\\output'           \n",
    "\n",
    "end_date = str(today)\n",
    "\n",
    "# vale, la proyeccion es con base en el año anterior entonces, se necesita un query grande, en este caso se toma desde la primera semana del año anterior                                    \n",
    "df_inv_ventas_hist = gd.get_inv_venta_hist(BU, div, '2022-01-09', end_date, carpeta_input, carpeta_output, 33)\n",
    "\n",
    "#T117 2112513083\n",
    "print(\"Detectando semanas faltantes... \") #-------------------------------------------------------------------------------------------------\n",
    "# Aquí se crea un rango de fechas para cada SKU y tienda\n",
    "\n",
    "# Creando un dataframe con los datos faltantes\n",
    "datos_faltantes = pd.DataFrame(columns=df_inv_ventas_hist.columns)\n",
    "numero_datos_faltantes = pd.DataFrame(columns=['Location Code', 'SKU', 'Cantidad'])\n",
    "\n",
    "SKUS = df_inv_ventas_hist['SKU'].unique()\n",
    "for sku in SKUS: \n",
    "    df = df_inv_ventas_hist[df_inv_ventas_hist['SKU'] == sku] # for\n",
    "    tiendas = df['Location Code'].unique()\n",
    "    for tienda in tiendas:\n",
    "        df_tienda = df[df['Location Code'] == tienda]\n",
    "\n",
    "        first_week = df_tienda[\"Date\"].min().strftime(\"%Y-%m-%d\")\n",
    "        last_week = df_tienda[\"Date\"].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Se crea un rango de fechas con el fin de identificar si hay datos faltantes\n",
    "        weeks = pd.date_range(start=first_week, end=last_week, freq='W')\n",
    "\n",
    "        # Se crea un dataframe con el rango de fechas\n",
    "        df_weeks = pd.DataFrame(weeks, columns=['Date'])\n",
    "\n",
    "        df_tienda = pd.merge(df_weeks, df_tienda, how='left', on='Date')\n",
    "\n",
    "        # Se rellenan los datos faltantes con nan\n",
    "        df_tienda = df_tienda.fillna(np.nan)\n",
    "\n",
    "        # Se rellenan los vacios con interpolacion lineal * deje ID con nans para identificarlos\n",
    "        \n",
    "        df_tienda['Inventario'] = df_tienda['Inventario'].interpolate()\n",
    "        df_tienda['Ventas'] = df_tienda['Ventas'].interpolate()\n",
    "\n",
    "        df_tienda['Location Code'].fillna(tienda, inplace=True)\n",
    "        df_tienda['SKU'].fillna(sku, inplace=True)\n",
    "\n",
    "        Cantidad = df_tienda['ID'].isna().sum()\n",
    "        faltantes = pd.DataFrame({'Location Code': tienda, 'SKU': sku, 'Cantidad': Cantidad}, index=[0])\n",
    "        numero_datos_faltantes = pd.concat([numero_datos_faltantes, faltantes])\n",
    "\n",
    "        # Se agrega en el dataframe de datos faltantes\n",
    "        datos_faltantes = pd.concat([datos_faltantes, df_tienda[df_tienda['ID'].isna()]])\n",
    "\n",
    "        # tiempo interpolacion 1 min 40 seg\n",
    "        # 54 seg\n",
    "        # 48 seg\n",
    "\n",
    "df_inv_ventas_hist['Date'] = pd.to_datetime(df_inv_ventas_hist['Date'])\n",
    "df_inv_ventas_hist = pd.concat([df_inv_ventas_hist, datos_faltantes]).reset_index(drop=True)\n",
    "df_inv_ventas_hist = df_inv_ventas_hist.sort_values(by=['SKU', 'Location Code', 'Date']).reset_index(drop=True) ##\n",
    "\n",
    "print('Porcentaje de datos interpolados:', str((df_inv_ventas_hist['ID'].isnull().sum() / len(df_inv_ventas_hist))*100) + '%')\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    # Single batch\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_inv_ventas_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fcolin\\Documents\\DataScience - Merchandaising\\BuffersBasicosV1\\code\\Pruebas.ipynb Celda 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m df_inv_ventas_hist[[\u001b[39m'\u001b[39m\u001b[39mSKU\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLocation Code\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVentas\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mInventario\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mLocation Code\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_inv_ventas_hist' is not defined"
     ]
    }
   ],
   "source": [
    "data = df_inv_ventas_hist[['SKU', 'Location Code', 'Ventas', 'Inventario', 'Date']]\n",
    "data['Location Code'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_20204\\712706890.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Location Code'] =  data['Location Code'].astype('category')\n",
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_20204\\712706890.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Location Code'] = data['Location Code'].cat.codes\n"
     ]
    }
   ],
   "source": [
    "# encode Location Code\n",
    "data['Location Code'] =  data['Location Code'].astype('category')\n",
    "data['Location Code'] = data['Location Code'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_20204\\1299829324.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Date'] = pd.to_datetime(data['Date'])\n",
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_20204\\1299829324.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Date'] = data['Date'].astype('category')\n",
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_20204\\1299829324.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Date'] = data['Date'].cat.codes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56], dtype=int8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Econde date\n",
    "data.loc[0,'Date']\n",
    "# transform timestamp to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "# encode \n",
    "\n",
    "data['Date'] = data['Date'].astype('category')\n",
    "data['Date'] = data['Date'].cat.codes\n",
    "\n",
    "data['Date'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    \"\"\"Helper function to plot our time series\"\"\"\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(False)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    \"\"\"Define the trend through slope and time\"\"\"\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Arbitrary definition of a seasonality pattern\"\"\"\n",
    "    return np.where(season_time < 0.1,\n",
    "                    np.cos(season_time * 6 * np.pi),\n",
    "                    2 / np.exp(9 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repeats a pattern at each period\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    \"\"\"Adds white noise to the series\"\"\"\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level\n",
    "\n",
    "def generate_time_series():\n",
    "    # Temporal dimension: 4 years of data\n",
    "    time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "\n",
    "    # The initial series is nothing more than a straight line which we will then modify with the other functions\n",
    "    y_intercept = 10\n",
    "    slope = 0.005\n",
    "    series = trend(time, slope) + y_intercept\n",
    "\n",
    "    # Add seasonality\n",
    "    amplitude = 50\n",
    "    series += seasonality(time, period=365, amplitude=amplitude)\n",
    "\n",
    "    # Add noise\n",
    "    noise_level = 3\n",
    "    series += noise(time, noise_level, seed=51)\n",
    "    \n",
    "    return time, series\n",
    "\n",
    "\n",
    "# Let's save the parameters of our time series in the dataclass\n",
    "#@dataclass\n",
    "class G:\n",
    "    TIME, SERIES = generate_time_series()\n",
    "    SPLIT_TIME = 1100 # on day 1100 the training period will end. The rest will belong to the validation set\n",
    "    WINDOW_SIZE = 20 # how many data points will we take into account to make our prediction\n",
    "    BATCH_SIZE = 32 # how many items will we supply per batch\n",
    "    SHUFFLE_BUFFER_SIZE = 1000 # we need this parameter to define the Tensorflow sample buffer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_val_split(time, series, time_step=G.SPLIT_TIME):\n",
    "\t\"\"\"Divide the time series into training and validation set\"\"\"\n",
    "\ttime_train = time[:time_step]\n",
    "\tseries_train = series[:time_step]\n",
    "\ttime_valid = time[time_step:]\n",
    "\tseries_valid = series[time_step:]\n",
    "\n",
    "\treturn time_train, series_train, time_valid, series_valid\n",
    "\n",
    "def windowed_dataset(series, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE):\n",
    "\t\"\"\"\n",
    "\tWe create time windows to create X and y features.\n",
    "\tFor example, if we choose a window of 30, we will create a dataset formed by 30 points as X\n",
    "\t\"\"\"\n",
    "\tdataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\tdataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "\tdataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\tdataset = dataset.shuffle(shuffle_buffer)\n",
    "\tdataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\tdataset = dataset.batch(batch_size).prefetch(1)\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WindowDataset element_spec=DatasetSpec(TensorSpec(shape=(), dtype=tf.int64, name=None), TensorShape([]))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.097e+03, 1.098e+03,\n",
       "        1.099e+03], dtype=float32),\n",
       " array([59.12849 , 60.274727, 63.495922, ..., 65.180084, 62.56855 ,\n",
       "        63.612823], dtype=float32),\n",
       " array([1100., 1101., 1102., 1103., 1104., 1105., 1106., 1107., 1108.,\n",
       "        1109., 1110., 1111., 1112., 1113., 1114., 1115., 1116., 1117.,\n",
       "        1118., 1119., 1120., 1121., 1122., 1123., 1124., 1125., 1126.,\n",
       "        1127., 1128., 1129., 1130., 1131., 1132., 1133., 1134., 1135.,\n",
       "        1136., 1137., 1138., 1139., 1140., 1141., 1142., 1143., 1144.,\n",
       "        1145., 1146., 1147., 1148., 1149., 1150., 1151., 1152., 1153.,\n",
       "        1154., 1155., 1156., 1157., 1158., 1159., 1160., 1161., 1162.,\n",
       "        1163., 1164., 1165., 1166., 1167., 1168., 1169., 1170., 1171.,\n",
       "        1172., 1173., 1174., 1175., 1176., 1177., 1178., 1179., 1180.,\n",
       "        1181., 1182., 1183., 1184., 1185., 1186., 1187., 1188., 1189.,\n",
       "        1190., 1191., 1192., 1193., 1194., 1195., 1196., 1197., 1198.,\n",
       "        1199., 1200., 1201., 1202., 1203., 1204., 1205., 1206., 1207.,\n",
       "        1208., 1209., 1210., 1211., 1212., 1213., 1214., 1215., 1216.,\n",
       "        1217., 1218., 1219., 1220., 1221., 1222., 1223., 1224., 1225.,\n",
       "        1226., 1227., 1228., 1229., 1230., 1231., 1232., 1233., 1234.,\n",
       "        1235., 1236., 1237., 1238., 1239., 1240., 1241., 1242., 1243.,\n",
       "        1244., 1245., 1246., 1247., 1248., 1249., 1250., 1251., 1252.,\n",
       "        1253., 1254., 1255., 1256., 1257., 1258., 1259., 1260., 1261.,\n",
       "        1262., 1263., 1264., 1265., 1266., 1267., 1268., 1269., 1270.,\n",
       "        1271., 1272., 1273., 1274., 1275., 1276., 1277., 1278., 1279.,\n",
       "        1280., 1281., 1282., 1283., 1284., 1285., 1286., 1287., 1288.,\n",
       "        1289., 1290., 1291., 1292., 1293., 1294., 1295., 1296., 1297.,\n",
       "        1298., 1299., 1300., 1301., 1302., 1303., 1304., 1305., 1306.,\n",
       "        1307., 1308., 1309., 1310., 1311., 1312., 1313., 1314., 1315.,\n",
       "        1316., 1317., 1318., 1319., 1320., 1321., 1322., 1323., 1324.,\n",
       "        1325., 1326., 1327., 1328., 1329., 1330., 1331., 1332., 1333.,\n",
       "        1334., 1335., 1336., 1337., 1338., 1339., 1340., 1341., 1342.,\n",
       "        1343., 1344., 1345., 1346., 1347., 1348., 1349., 1350., 1351.,\n",
       "        1352., 1353., 1354., 1355., 1356., 1357., 1358., 1359., 1360.,\n",
       "        1361., 1362., 1363., 1364., 1365., 1366., 1367., 1368., 1369.,\n",
       "        1370., 1371., 1372., 1373., 1374., 1375., 1376., 1377., 1378.,\n",
       "        1379., 1380., 1381., 1382., 1383., 1384., 1385., 1386., 1387.,\n",
       "        1388., 1389., 1390., 1391., 1392., 1393., 1394., 1395., 1396.,\n",
       "        1397., 1398., 1399., 1400., 1401., 1402., 1403., 1404., 1405.,\n",
       "        1406., 1407., 1408., 1409., 1410., 1411., 1412., 1413., 1414.,\n",
       "        1415., 1416., 1417., 1418., 1419., 1420., 1421., 1422., 1423.,\n",
       "        1424., 1425., 1426., 1427., 1428., 1429., 1430., 1431., 1432.,\n",
       "        1433., 1434., 1435., 1436., 1437., 1438., 1439., 1440., 1441.,\n",
       "        1442., 1443., 1444., 1445., 1446., 1447., 1448., 1449., 1450.,\n",
       "        1451., 1452., 1453., 1454., 1455., 1456., 1457., 1458., 1459.,\n",
       "        1460.], dtype=float32),\n",
       " array([65.15959  , 65.14456  , 57.292316 , 60.968033 , 56.14131  ,\n",
       "        53.25669  , 59.297207 , 54.972786 , 57.620403 , 52.93291  ,\n",
       "        48.156208 , 54.255863 , 50.78543  , 39.16272  , 42.533253 ,\n",
       "        40.31558  , 39.592094 , 37.946262 , 33.246212 , 33.518856 ,\n",
       "        24.433868 , 25.58668  , 25.990997 , 20.378044 , 18.585783 ,\n",
       "        14.176069 , 15.9315   ,  9.870104 , 12.033117 ,  3.6253889,\n",
       "         7.3243637,  4.5468636, 53.277737 , 54.935707 , 52.066517 ,\n",
       "        51.55519  , 46.09124  , 48.638844 , 42.159466 , 54.596462 ,\n",
       "        49.3601   , 47.66022  , 52.912823 , 43.772926 , 40.098736 ,\n",
       "        46.938286 , 49.036156 , 43.949245 , 43.8669   , 43.23741  ,\n",
       "        41.68744  , 41.139297 , 41.79848  , 37.51507  , 34.17163  ,\n",
       "        43.796047 , 36.926796 , 37.076675 , 33.653263 , 42.888237 ,\n",
       "        33.458183 , 33.54448  , 32.03874  , 36.376396 , 35.49529  ,\n",
       "        32.602737 , 36.408802 , 32.63415  , 31.771963 , 30.916378 ,\n",
       "        29.566275 , 32.00381  , 31.924849 , 30.473616 , 27.576597 ,\n",
       "        31.953096 , 30.750416 , 28.050776 , 28.406841 , 31.126812 ,\n",
       "        31.128408 , 23.199434 , 30.515713 , 26.867302 , 23.66657  ,\n",
       "        24.485952 , 22.624512 , 25.591236 , 24.967201 , 29.52207  ,\n",
       "        25.879953 , 24.04361  , 24.735243 , 23.452345 , 26.135923 ,\n",
       "        26.405212 , 23.759092 , 25.471136 , 29.888796 , 21.690458 ,\n",
       "        23.203548 , 24.102423 , 22.329048 , 29.29256  , 18.093018 ,\n",
       "        22.08619  , 21.422638 , 20.634893 , 26.98126  , 25.245092 ,\n",
       "        15.201954 , 20.414192 , 26.217836 , 24.358171 , 23.248577 ,\n",
       "        18.168985 , 18.688349 , 14.283987 , 18.191618 , 22.03415  ,\n",
       "        22.503855 , 22.1335   , 19.005875 , 17.359951 , 16.249905 ,\n",
       "        17.022408 , 19.52565  , 26.048641 , 20.676626 , 18.733372 ,\n",
       "        22.134556 , 20.13827  , 15.743742 , 22.10413  , 21.454632 ,\n",
       "        13.754781 , 20.20977  , 16.89176  , 14.561734 , 17.603687 ,\n",
       "        21.92833  , 16.59133  , 23.629873 , 16.30466  , 17.055834 ,\n",
       "        18.120388 , 23.186384 , 20.702278 , 16.634575 , 14.905163 ,\n",
       "        13.712793 , 21.219618 , 15.955251 , 22.205975 , 13.926345 ,\n",
       "        20.555975 , 18.8342   , 19.377151 , 15.787677 , 15.12607  ,\n",
       "        17.586555 , 19.809381 , 20.237099 , 16.81724  , 18.930256 ,\n",
       "        17.79907  , 15.852769 , 18.237654 , 16.214218 , 11.501604 ,\n",
       "        22.07485  , 18.216072 , 10.609177 , 18.590324 , 22.608797 ,\n",
       "        14.278907 , 20.671991 , 15.910901 , 17.977638 , 17.09139  ,\n",
       "        14.624489 , 18.725939 , 13.133755 , 19.031893 , 20.33677  ,\n",
       "        18.642162 , 18.387447 , 16.655832 , 15.519707 , 15.48357  ,\n",
       "        15.784246 , 17.92099  , 13.1995325, 16.016932 , 13.10196  ,\n",
       "         9.863117 , 20.226671 , 13.542977 , 15.962083 , 17.363928 ,\n",
       "        17.799713 , 16.23719  , 14.767593 , 15.2263565, 14.4951935,\n",
       "        18.740484 , 17.930567 , 17.640074 , 16.97401  , 14.371064 ,\n",
       "        15.70692  , 20.281206 , 12.898134 , 19.773878 , 19.945698 ,\n",
       "        18.777004 , 16.48567  , 17.3376   , 17.56061  , 17.282867 ,\n",
       "        21.044188 , 13.723491 , 15.950567 , 20.806553 , 18.241976 ,\n",
       "        15.645816 , 14.562738 , 18.976795 , 18.101826 ,  9.918443 ,\n",
       "        14.340566 , 13.595131 , 17.328382 , 18.884268 , 12.382625 ,\n",
       "        14.12132  , 20.186512 , 13.6101265, 16.101334 , 17.387825 ,\n",
       "        15.063471 , 15.364647 , 19.88607  , 17.956629 , 20.738678 ,\n",
       "        18.422537 , 18.157955 , 15.962694 , 19.846405 , 14.673823 ,\n",
       "        10.13749  , 15.883993 , 13.530601 , 11.322488 , 20.649551 ,\n",
       "        18.32861  , 14.438668 , 12.863456 , 19.556522 , 14.867896 ,\n",
       "        14.885467 , 24.32207  , 20.421328 , 16.672949 , 19.461308 ,\n",
       "        11.713074 , 12.585718 , 10.500992 , 16.34832  , 16.54424  ,\n",
       "        15.793876 , 22.234745 , 22.326077 , 18.068718 , 12.738453 ,\n",
       "        14.266198 , 17.093084 , 17.68093  , 17.635738 , 19.542744 ,\n",
       "        21.809944 , 13.890272 , 15.077767 , 14.354536 , 16.488184 ,\n",
       "        18.451189 , 17.774729 , 10.983698 , 11.776628 , 17.087978 ,\n",
       "        14.995899 , 21.030857 , 17.664204 , 24.441772 , 17.691843 ,\n",
       "        20.08423  , 18.887941 , 13.213798 , 11.350764 , 18.868092 ,\n",
       "        19.879826 , 12.896705 , 13.311444 , 17.263968 , 19.222427 ,\n",
       "        16.51709  , 16.75575  , 17.15516  , 23.720251 , 22.04407  ,\n",
       "        15.080962 , 17.584661 , 20.218904 , 15.430411 , 18.938026 ,\n",
       "        23.366758 , 12.815922 , 14.117774 , 17.48814  , 15.945344 ,\n",
       "        17.919937 , 13.890385 , 25.12651  , 18.492208 , 21.63661  ,\n",
       "        10.252216 , 18.000778 , 21.573265 , 18.707298 , 13.9344845,\n",
       "        13.77948  , 15.339831 , 20.466827 , 22.358438 , 12.892554 ,\n",
       "        23.836622 , 19.84064  , 14.580377 , 25.504793 , 19.021513 ,\n",
       "        17.248941 , 18.474396 , 14.787133 , 17.570986 , 16.41075  ,\n",
       "        15.400239 , 23.306244 , 13.186605 , 13.658152 , 16.467451 ,\n",
       "        22.649483 , 18.728392 , 19.232597 , 15.898961 , 15.192256 ,\n",
       "        16.733074 , 12.564289 , 18.978737 , 12.111265 , 18.541754 ,\n",
       "        71.360245 ], dtype=float32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "\n",
    "'''for window_dataset in dataset:\n",
    "    for val in window_dataset:\n",
    "        print(val.numpy(), end=\" \")\n",
    "    print()'''\n",
    "\n",
    "# let's create the dataset with time windows\n",
    "dataset = windowed_dataset(G.SERIES, G.WINDOW_SIZE, G.BATCH_SIZE, G.SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "# we divide into training and validation set\n",
    "train_val_split(G.TIME, G.SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(producto, tienda)\n",
    "        \n",
    "df = df_inv_ventas_hist[(df_inv_ventas_hist['SKU'] == producto) & (df_inv_ventas_hist['Location Code'] == tienda)].reset_index(drop=True)\n",
    "df = df[['Date', 'Ventas']]\n",
    "df['Ventas']= df['Ventas'].astype(int)\n",
    "\n",
    "# ordenando por fecha\n",
    "df = df.sort_values(by=['Date']).reset_index(drop=True)\n",
    "df['time'] = range(len(df))\n",
    "\n",
    "time = df['time'].values\n",
    "series = df['Ventas'].values\n",
    "\n",
    "# Define the split time\n",
    "split_time = int(round(len(df)*0.80,0))\n",
    "\n",
    "# Get the train set \n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "\n",
    "# Get the validation set\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]    \n",
    "\n",
    "window_size = 4\n",
    "batch_size = 30\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)    \n",
    "\n",
    "l0 = tf.keras.layers.Dense(1, input_shape=[window_size])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
    "                    strides=1, padding=\"causal\",\n",
    "                    activation=\"relu\",\n",
    "                    input_shape=[window_size, 1]),\n",
    "tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "tf.keras.layers.LSTM(64),\n",
    "tf.keras.layers.Dense(1),\n",
    "tf.keras.layers.Lambda(lambda x: x * 400)\n",
    "])\n",
    "\n",
    "#model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9), metrics=[\"accuracy\"])\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9), metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(dataset,epochs=100)\n",
    "\n",
    "# Todo esto es para hacer el forecast en el tiempo de validacion\n",
    "'''forecast = []\n",
    "for time in range(len(series) - window_size):\n",
    "    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
    "\n",
    "forecast = forecast[split_time - window_size:]\n",
    "results = np.array(forecast).squeeze()\n",
    "\n",
    "#Convert to a numpy array and drop single dimensional axes\n",
    "results = np.array(forecast).squeeze()\n",
    "results = np.round(abs(results), 0)\n",
    "\n",
    "# Overlay the results with the validation set\n",
    "time = df['time'].values\n",
    "series = df['Ventas'].values\n",
    "forecast = forecast[split_time - window_size:]\n",
    "# plot_series(time_valid, (x_valid, abs(results)))\n",
    "\n",
    "#print(\"Real: \", sum(x_valid[-7:]))\n",
    "#print(\"Proyectada: \", sum(abs(results[-7:])))\n",
    "\n",
    "#print(tf.keras.metrics.mean_squared_error(x_valid, results).numpy())\n",
    "#print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d8efc0accedf8a71318180958b2a2c3ace073b5a0267b0b56f49dfe74d51c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
