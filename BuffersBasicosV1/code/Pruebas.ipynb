{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "BU = 'BEAUTY'\n",
    "today = datetime.date.today()\n",
    "carpeta_input = R'S:\\BI\\16. DATA SCIENCE\\9_Buffers\\BuffersBasicosV1\\input'\n",
    "carpeta_output = R'S:\\BI\\16. DATA SCIENCE\\9_Buffers\\BuffersBasicosV1\\output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consultando inventarios... \n",
      "Consultando ventas... \n",
      "Consultando clones... \n",
      "Preparando data... \n",
      "Identificando características de tiendas y productos....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import get_data as gd\n",
    "\n",
    "\n",
    "div =   {'BEAUTY': \"[Division Code] = 'BEAUTY'\", \n",
    "            'JEW': \"[Division Code] IN ('W-JEW', 'M-JEW')\",\n",
    "            'ACC': \"[Division Code] IN ('W-ACC', 'M-ACC')\",\n",
    "        'CALZADO':\"[Division Code] in ('W-SHO','M-SHO')\",\n",
    "           'ROPA':\"[Division Code] in ('W-CLO','M-CLO')\"} \n",
    "   \n",
    "end_date = str(today)\n",
    "\n",
    "# vale, la proyeccion es con base en el año anterior entonces, se necesita un query grande, en este caso se toma desde la primera semana del año anterior                                    \n",
    "df_inv_ventas_hist = gd.get_inv_venta_hist(BU, div, '2022-01-09', end_date, carpeta_input, carpeta_output, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inv_ventas_hist['ID'].str[6:].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectando semanas faltantes... \n",
      "Porcentaje de datos interpolados: 1.2445220300765552%\n"
     ]
    }
   ],
   "source": [
    "#T117 2112513083\n",
    "print(\"Detectando semanas faltantes... \") #-------------------------------------------------------------------------------------------------\n",
    "# Aquí se crea un rango de fechas para cada SKU y tienda\n",
    "\n",
    "# Creando un dataframe con los datos faltantes\n",
    "datos_faltantes = pd.DataFrame(columns=df_inv_ventas_hist.columns)\n",
    "numero_datos_faltantes = pd.DataFrame(columns=['Location Code', 'SKU', 'Cantidad'])\n",
    "\n",
    "SKUS = df_inv_ventas_hist['SKU'].unique()\n",
    "for sku in SKUS: \n",
    "    df = df_inv_ventas_hist[df_inv_ventas_hist['SKU'] == sku] # for\n",
    "    tiendas = df['Location Code'].unique()\n",
    "    for tienda in tiendas:\n",
    "        df_tienda = df[df['Location Code'] == tienda]\n",
    "\n",
    "        first_week = df_tienda[\"Date\"].min().strftime(\"%Y-%m-%d\")\n",
    "        last_week = df_tienda[\"Date\"].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Se crea un rango de fechas con el fin de identificar si hay datos faltantes\n",
    "        weeks = pd.date_range(start=first_week, end=last_week, freq='W')\n",
    "\n",
    "        # Se crea un dataframe con el rango de fechas\n",
    "        df_weeks = pd.DataFrame(weeks, columns=['Date'])\n",
    "\n",
    "        df_tienda = pd.merge(df_weeks, df_tienda, how='left', on='Date')\n",
    "\n",
    "        # Se rellenan los datos faltantes con nan\n",
    "        df_tienda = df_tienda.fillna(np.nan)\n",
    "\n",
    "        # Se rellenan los vacios con interpolacion lineal * deje ID con nans para identificarlos\n",
    "        \n",
    "        df_tienda['Inventario'] = df_tienda['Inventario'].interpolate()\n",
    "        df_tienda['Ventas'] = df_tienda['Ventas'].interpolate()\n",
    "\n",
    "        df_tienda['Location Code'].fillna(tienda, inplace=True)\n",
    "        df_tienda['SKU'].fillna(sku, inplace=True)\n",
    "\n",
    "        Cantidad = df_tienda['ID'].isna().sum()\n",
    "        faltantes = pd.DataFrame({'Location Code': tienda, 'SKU': sku, 'Cantidad': Cantidad}, index=[0])\n",
    "        numero_datos_faltantes = pd.concat([numero_datos_faltantes, faltantes])\n",
    "\n",
    "        # Se agrega en el dataframe de datos faltantes\n",
    "        datos_faltantes = pd.concat([datos_faltantes, df_tienda[df_tienda['ID'].isna()]])\n",
    "\n",
    "        # tiempo interpolacion 1 min 40 seg\n",
    "        # 54 seg\n",
    "        # 48 seg\n",
    "\n",
    "df_inv_ventas_hist['Date'] = pd.to_datetime(df_inv_ventas_hist['Date'])\n",
    "df_inv_ventas_hist = pd.concat([df_inv_ventas_hist, datos_faltantes]).reset_index(drop=True)\n",
    "df_inv_ventas_hist = df_inv_ventas_hist.sort_values(by=['SKU', 'Location Code', 'Date']).reset_index(drop=True) ##\n",
    "\n",
    "print('Porcentaje de datos interpolados:', str((df_inv_ventas_hist['ID'].isnull().sum() / len(df_inv_ventas_hist))*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    # Single batch\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112513083 T117\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 29ms/step - loss: 24.2494 - mae: 24.7494\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0572 - mae: 23.5572\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.5634 - mae: 21.0634\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.0692 - mae: 17.5667\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1285 - mae: 13.6257\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4931 - mae: 9.9925\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4823 - mae: 7.9714\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7257 - mae: 7.2030\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.9197 - mae: 7.3982\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3284 - mae: 7.8143\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.3664 - mae: 7.8366\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9139 - mae: 7.3896\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.2267 - mae: 6.7164\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 5.6976 - mae: 6.1837\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.8268 - mae: 6.3220\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0208 - mae: 6.5068\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9200 - mae: 6.3979\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5450 - mae: 6.0323\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1157 - mae: 5.6155\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.8458 - mae: 5.3433\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.7069 - mae: 5.1978\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.4645 - mae: 4.9445\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.0233 - mae: 4.5152\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5753 - mae: 4.0589\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8713 - mae: 4.3570\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.6038 - mae: 5.0953\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.6430 - mae: 5.1377\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.3598 - mae: 4.8471\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.2623 - mae: 4.7322\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.8864 - mae: 4.3680\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.2473 - mae: 3.7376\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.5565 - mae: 3.0274\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0682 - mae: 2.5293\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4023 - mae: 2.8807\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2398 - mae: 3.7305\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5796 - mae: 4.0627\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9713 - mae: 3.4616\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9419 - mae: 2.4310\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9402 - mae: 2.3994\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.8572 - mae: 3.3247\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.9214 - mae: 3.3828\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1862 - mae: 2.6481\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6820 - mae: 2.1419\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5975 - mae: 2.0455\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.6192 - mae: 2.0805\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8996 - mae: 2.3654\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5474 - mae: 3.0011\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.9924 - mae: 3.4773\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.4754 - mae: 2.9131\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.7275 - mae: 2.2025\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6340 - mae: 2.0760\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.8119 - mae: 2.2824\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6507 - mae: 2.0899\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5416 - mae: 1.9706\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5345 - mae: 1.9977\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7169 - mae: 2.1886\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.2726 - mae: 2.7344\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.6221 - mae: 3.0843\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1598 - mae: 2.6255\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7026 - mae: 2.1795\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.5982 - mae: 2.0519\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6134 - mae: 2.0672\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6061 - mae: 2.0526\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5916 - mae: 2.0226\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6323 - mae: 2.0947\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.9682 - mae: 2.4186\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1525 - mae: 2.6209\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.0888 - mae: 2.5534\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9525 - mae: 2.4026\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6379 - mae: 2.1002\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.9107 - mae: 2.3968\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.3347 - mae: 2.7682\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1691 - mae: 2.6172\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6824 - mae: 2.1461\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8791 - mae: 2.3329\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.4437 - mae: 2.9023\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.2400 - mae: 2.6988\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8882 - mae: 2.3357\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8068 - mae: 2.2510\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7665 - mae: 2.2108\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.7443 - mae: 2.1982\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8972 - mae: 2.3357\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9130 - mae: 2.3542\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7910 - mae: 2.2452\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.7881 - mae: 2.2440\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.7399 - mae: 2.1957\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6970 - mae: 2.1360\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6699 - mae: 2.1120\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6313 - mae: 2.0718\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7455 - mae: 2.2065\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9911 - mae: 2.4547\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.2993 - mae: 2.7580\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2804 - mae: 2.7485\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7498 - mae: 2.2123\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4545 - mae: 1.8903\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6426 - mae: 2.1086\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2410 - mae: 2.7017\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0659 - mae: 3.5309\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1326 - mae: 3.5967\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1859 - mae: 2.6461\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def proyeccion_RNN(producto, tienda):\n",
    "    print(producto, tienda)\n",
    "        \n",
    "    df = df_inv_ventas_hist[(df_inv_ventas_hist['SKU'] == producto) & (df_inv_ventas_hist['Location Code'] == tienda)].reset_index(drop=True)\n",
    "    df = df[['Date', 'Ventas']]\n",
    "    df['Ventas']= df['Ventas'].astype(int)\n",
    "\n",
    "    # ordenando por fecha\n",
    "    df = df.sort_values(by=['Date']).reset_index(drop=True)\n",
    "    df['time'] = range(len(df))\n",
    "\n",
    "    time = df['time'].values\n",
    "    series = df['Ventas'].values\n",
    "\n",
    "    # Define the split time\n",
    "    split_time = int(round(len(df)*0.80,0))\n",
    "\n",
    "    # Get the train set \n",
    "    time_train = time[:split_time]\n",
    "    x_train = series[:split_time]\n",
    "\n",
    "    # Get the validation set\n",
    "    time_valid = time[split_time:]\n",
    "    x_valid = series[split_time:]    \n",
    "\n",
    "    window_size = 4\n",
    "    batch_size = 30\n",
    "    shuffle_buffer_size = 1000\n",
    "\n",
    "    dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)    \n",
    "\n",
    "    l0 = tf.keras.layers.Dense(1, input_shape=[window_size])\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
    "                        strides=1, padding=\"causal\",\n",
    "                        activation=\"relu\",\n",
    "                        input_shape=[window_size, 1]),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
    "    ])\n",
    "\n",
    "    #model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9), metrics=[\"accuracy\"])\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9), metrics=[\"mae\"])\n",
    "\n",
    "    history = model.fit(dataset,epochs=100)\n",
    "\n",
    "    '''forecast = []\n",
    "    for time in range(len(series) - window_size):\n",
    "        forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
    "\n",
    "    forecast = forecast[split_time - window_size:]\n",
    "    results = np.array(forecast).squeeze()\n",
    "\n",
    "    #Convert to a numpy array and drop single dimensional axes\n",
    "    results = np.array(forecast).squeeze()\n",
    "    results = np.round(abs(results), 0)\n",
    "\n",
    "    # Overlay the results with the validation set\n",
    "    time = df['time'].values\n",
    "    series = df['Ventas'].values\n",
    "    forecast = forecast[split_time - window_size:]\n",
    "    # plot_series(time_valid, (x_valid, abs(results)))\n",
    "\n",
    "    #print(\"Real: \", sum(x_valid[-7:]))\n",
    "    #print(\"Proyectada: \", sum(abs(results[-7:])))\n",
    "\n",
    "    #print(tf.keras.metrics.mean_squared_error(x_valid, results).numpy())\n",
    "    #print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())'''\n",
    "\n",
    "    ultima_fecha = str(df.loc[(len(df)-1),'Date'])[:10]\n",
    "    ultima_fecha = datetime.strptime(ultima_fecha, '%Y-%m-%d')\n",
    "    from datetime import timedelta\n",
    "\n",
    "    size_proyeccion = 8\n",
    "    fechas_proyeccion = []\n",
    "    forecast = []\n",
    "\n",
    "    #series = series[:split_time]\n",
    "\n",
    "    for i in range(size_proyeccion):\n",
    "        forecast.append(model.predict(series[-window_size:][np.newaxis]))\n",
    "        series = np.append(series, abs(int(forecast[-1].squeeze())))\n",
    "        ultima_fecha = ultima_fecha + timedelta(days=7)\n",
    "        fechas_proyeccion.append(ultima_fecha)\n",
    "        i = i + 1\n",
    "        \n",
    "    #print('Real: ', sum(series2[split_time:split_time+8]))\n",
    "    #print('Proyectada: ', sum(series[-8:]))\n",
    "    #print(\"Actual: \", (series2[split_time:split_time+8]).mean()*8)\n",
    "    #plot_series(time_valid[:8], (series2[split_time:split_time+8], series[-8:]))\n",
    "    proyeccion = series[-size_proyeccion:]\n",
    "    \n",
    "    b = pd.DataFrame({'Fecha':fechas_proyeccion, 'Proyeccion':proyeccion})\n",
    "    b['SKU'] = producto\n",
    "    b['Tienda'] = tienda\n",
    "    #Proyecciones = pd.concat([Proyecciones, b], axis=0)\n",
    "\n",
    "\n",
    "    mae=history.history['mae'][-1]\n",
    "    loss=history.history['loss'][-1]\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    return b, loss, mae\n",
    "\n",
    "#producto = '2112513083'\n",
    "#tienda = 'T117'    \n",
    "#bd, loss, mae = proyeccion_RNN(producto, tienda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1215560051 E002\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 3s 24ms/step - loss: 5.8655 - mae: 6.3130\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.9336 - mae: 5.4073\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.1087 - mae: 4.5890\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.9230 - mae: 4.3964\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.0825 - mae: 4.5623\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.9387 - mae: 4.4187\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.5560 - mae: 4.0292\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.2453 - mae: 3.7112\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.1560 - mae: 3.6141\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.0686 - mae: 3.5226\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.8416 - mae: 3.3060\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.6690 - mae: 3.1408\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.4499 - mae: 2.9133\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2881 - mae: 2.7470\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0991 - mae: 2.5537\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9392 - mae: 2.3852\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8102 - mae: 2.2527\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.6613 - mae: 2.0971\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5088 - mae: 1.9309\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.3964 - mae: 1.8152\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2788 - mae: 1.6885\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2087 - mae: 1.6303\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1206 - mae: 1.5301\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0670 - mae: 1.4369\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0178 - mae: 1.3722\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9812 - mae: 1.3400\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9414 - mae: 1.3117\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9212 - mae: 1.3038\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9083 - mae: 1.2960\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8965 - mae: 1.2969\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8916 - mae: 1.2999\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8827 - mae: 1.2934\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8758 - mae: 1.2825\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8789 - mae: 1.2841\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8753 - mae: 1.2862\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8744 - mae: 1.2885\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8729 - mae: 1.2865\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8648 - mae: 1.2822\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8703 - mae: 1.2899\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8611 - mae: 1.2779\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.8636 - mae: 1.2748\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8607 - mae: 1.2733\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8562 - mae: 1.2706\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8516 - mae: 1.2682\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8605 - mae: 1.2817\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8467 - mae: 1.2651\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8453 - mae: 1.2583\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8506 - mae: 1.2576\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8463 - mae: 1.2654\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8411 - mae: 1.2595\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8369 - mae: 1.2541\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8317 - mae: 1.2436\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8433 - mae: 1.2433\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8285 - mae: 1.2362\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8283 - mae: 1.2451\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8305 - mae: 1.2470\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8226 - mae: 1.2391\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8203 - mae: 1.2314\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8205 - mae: 1.2320\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8166 - mae: 1.2286\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8192 - mae: 1.2309\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8132 - mae: 1.2287\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8150 - mae: 1.2309\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8164 - mae: 1.2330\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8105 - mae: 1.2205\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8126 - mae: 1.2264\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8065 - mae: 1.2223\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7994 - mae: 1.2134\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8022 - mae: 1.2099\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7967 - mae: 1.2051\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7995 - mae: 1.2121\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7910 - mae: 1.2062\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8037 - mae: 1.2176\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7864 - mae: 1.1953\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7869 - mae: 1.1945\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7931 - mae: 1.1937\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7861 - mae: 1.1986\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7831 - mae: 1.1962\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7873 - mae: 1.2001\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7783 - mae: 1.1918\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7851 - mae: 1.2002\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7972 - mae: 1.2093\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7785 - mae: 1.1907\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7712 - mae: 1.1826\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7712 - mae: 1.1811\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7709 - mae: 1.1849\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7685 - mae: 1.1806\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7695 - mae: 1.1803\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7655 - mae: 1.1749\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7851 - mae: 1.1970\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7596 - mae: 1.1679\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7609 - mae: 1.1672\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7595 - mae: 1.1654\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7558 - mae: 1.1658\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7515 - mae: 1.1630\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7562 - mae: 1.1663\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7567 - mae: 1.1701\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7511 - mae: 1.1581\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7476 - mae: 1.1575\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7496 - mae: 1.1607\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1215560051 T001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_42424\\1929561199.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Status = Status.append({'SKU':producto, 'Tienda':tienda, 'loss':loss, 'mae':mae}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 7s 41ms/step - loss: 3.3808 - mae: 3.8611\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.0073 - mae: 3.4731\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.8154 - mae: 3.2967\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.8151 - mae: 3.2793\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.6824 - mae: 3.1429\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.4689 - mae: 2.9391\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.4484 - mae: 2.8944\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.3784 - mae: 2.8211\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2209 - mae: 2.6540\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.1669 - mae: 2.6038\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.1263 - mae: 2.5729\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.0334 - mae: 2.4696\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.0162 - mae: 2.4446\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.9841 - mae: 2.4113\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9326 - mae: 2.3637\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9210 - mae: 2.3638\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8964 - mae: 2.3411\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.8710 - mae: 2.3195\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.8555 - mae: 2.3077\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8457 - mae: 2.2946\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8253 - mae: 2.2807\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8003 - mae: 2.2546\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.7847 - mae: 2.2377\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.7734 - mae: 2.2266\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7614 - mae: 2.2124\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.7420 - mae: 2.1941\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7440 - mae: 2.1954\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7222 - mae: 2.1696\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7077 - mae: 2.1553\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.6883 - mae: 2.1384\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6813 - mae: 2.1305\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6586 - mae: 2.1087\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6486 - mae: 2.0956\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.6309 - mae: 2.0764\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6156 - mae: 2.0593\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6060 - mae: 2.0452\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6080 - mae: 2.0452\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.5910 - mae: 2.0298\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.5776 - mae: 2.0214\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5668 - mae: 2.0074\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5703 - mae: 2.0091\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5508 - mae: 1.9842\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5223 - mae: 1.9560\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.5118 - mae: 1.9456\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5004 - mae: 1.9340\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.4964 - mae: 1.9242\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4822 - mae: 1.9088\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.4679 - mae: 1.8986\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4636 - mae: 1.9025\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4514 - mae: 1.8909\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4382 - mae: 1.8675\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4318 - mae: 1.8591\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4245 - mae: 1.8521\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.4211 - mae: 1.8531\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.4037 - mae: 1.8343\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3984 - mae: 1.8354\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3857 - mae: 1.8211\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.3851 - mae: 1.8188\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3732 - mae: 1.8054\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3627 - mae: 1.7976\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3614 - mae: 1.7953\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3500 - mae: 1.7888\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3515 - mae: 1.7915\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3301 - mae: 1.7672\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3205 - mae: 1.7545\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.3196 - mae: 1.7566\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3074 - mae: 1.7475\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2990 - mae: 1.7392\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2945 - mae: 1.7355\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2834 - mae: 1.7249\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2781 - mae: 1.7189\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2707 - mae: 1.7110\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2752 - mae: 1.7198\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2597 - mae: 1.7027\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2601 - mae: 1.7058\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2458 - mae: 1.6893\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2404 - mae: 1.6814\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2353 - mae: 1.6734\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2262 - mae: 1.6663\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2253 - mae: 1.6707\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2172 - mae: 1.6629\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2103 - mae: 1.6484\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2168 - mae: 1.6515\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1978 - mae: 1.6407\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2063 - mae: 1.6507\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1988 - mae: 1.6449\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1926 - mae: 1.6351\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1920 - mae: 1.6294\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2062 - mae: 1.6538\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1859 - mae: 1.6312\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1540 - mae: 1.5997\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1911 - mae: 1.6212\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1818 - mae: 1.6196\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1496 - mae: 1.5871\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1687 - mae: 1.6160\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1429 - mae: 1.5831\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1370 - mae: 1.5742\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1357 - mae: 1.5737\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1280 - mae: 1.5686\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1300 - mae: 1.5720\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1215560051 T003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_42424\\1929561199.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Status = Status.append({'SKU':producto, 'Tienda':tienda, 'loss':loss, 'mae':mae}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 7s 29ms/step - loss: 3.6589 - mae: 4.1383\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.7581 - mae: 3.2286\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.3387 - mae: 2.8196\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.6568 - mae: 3.1301\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.6913 - mae: 3.1565\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.1942 - mae: 2.6532\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9965 - mae: 2.4481\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.0215 - mae: 2.4776\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.8149 - mae: 2.2685\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5182 - mae: 1.9619\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.4626 - mae: 1.9218\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3839 - mae: 1.8386\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1918 - mae: 1.6413\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0911 - mae: 1.5410\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9984 - mae: 1.4508\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9463 - mae: 1.3740\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8887 - mae: 1.3174\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8325 - mae: 1.2557\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8149 - mae: 1.2298\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7804 - mae: 1.1930\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7727 - mae: 1.2031\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7462 - mae: 1.1789\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7760 - mae: 1.2063\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7597 - mae: 1.1921\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7609 - mae: 1.1951\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7618 - mae: 1.1948\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7387 - mae: 1.1751\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7435 - mae: 1.1796\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7307 - mae: 1.1677\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7544 - mae: 1.1820\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7571 - mae: 1.1784\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7245 - mae: 1.1639\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7571 - mae: 1.1917\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7482 - mae: 1.1878\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7442 - mae: 1.1757\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7273 - mae: 1.1656\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7287 - mae: 1.1640\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7327 - mae: 1.1738\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7202 - mae: 1.1573\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7142 - mae: 1.1546\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7196 - mae: 1.1529\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7139 - mae: 1.1505\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7125 - mae: 1.1486\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7120 - mae: 1.1487\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7038 - mae: 1.1415\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7297 - mae: 1.1696\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7184 - mae: 1.1621\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7028 - mae: 1.1414\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7099 - mae: 1.1470\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6944 - mae: 1.1283\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6972 - mae: 1.1335\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6984 - mae: 1.1333\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6944 - mae: 1.1271\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6944 - mae: 1.1267\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6877 - mae: 1.1246\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6926 - mae: 1.1282\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6858 - mae: 1.1225\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6823 - mae: 1.1191\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6825 - mae: 1.1175\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6792 - mae: 1.1159\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6971 - mae: 1.1354\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6701 - mae: 1.1042\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7030 - mae: 1.1304\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6821 - mae: 1.1116\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6835 - mae: 1.1052\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7017 - mae: 1.1216\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6647 - mae: 1.1001\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6863 - mae: 1.1166\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6898 - mae: 1.1246\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6705 - mae: 1.1050\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6729 - mae: 1.1091\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6620 - mae: 1.1024\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6626 - mae: 1.0967\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6578 - mae: 1.0936\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6560 - mae: 1.0910\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6617 - mae: 1.0958\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6529 - mae: 1.0855\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6583 - mae: 1.0894\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6590 - mae: 1.0886\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6486 - mae: 1.0825\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6600 - mae: 1.0839\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6603 - mae: 1.0912\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6435 - mae: 1.0777\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6416 - mae: 1.0772\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6466 - mae: 1.0805\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6379 - mae: 1.0717\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6435 - mae: 1.0752\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6454 - mae: 1.0765\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6363 - mae: 1.0691\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6498 - mae: 1.0860\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6274 - mae: 1.0599\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6384 - mae: 1.0647\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6338 - mae: 1.0664\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6321 - mae: 1.0603\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6309 - mae: 1.0650\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6346 - mae: 1.0616\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6281 - mae: 1.0562\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6294 - mae: 1.0597\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6244 - mae: 1.0527\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6294 - mae: 1.0617\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1215560051 T004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_42424\\1929561199.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Status = Status.append({'SKU':producto, 'Tienda':tienda, 'loss':loss, 'mae':mae}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 3s 22ms/step - loss: 4.3261 - mae: 4.7707\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.1529 - mae: 3.6155\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.6028 - mae: 3.0648\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.9911 - mae: 3.4560\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.8221 - mae: 3.2914\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3629 - mae: 2.8023\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.2517 - mae: 2.7021\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1706 - mae: 2.6034\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8814 - mae: 2.2982\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8076 - mae: 2.2233\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.7152 - mae: 2.1569\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5399 - mae: 1.9138\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4653 - mae: 1.8774\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3362 - mae: 1.7243\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2680 - mae: 1.6302\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2043 - mae: 1.5540\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1118 - mae: 1.4898\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0757 - mae: 1.4628\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0136 - mae: 1.3745\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9861 - mae: 1.3381\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9649 - mae: 1.3230\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9355 - mae: 1.3056\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9261 - mae: 1.3024\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9055 - mae: 1.2899\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8971 - mae: 1.2858\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8868 - mae: 1.2757\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8806 - mae: 1.2727\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8700 - mae: 1.2592\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8704 - mae: 1.2582\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8753 - mae: 1.2662\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8637 - mae: 1.2646\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8680 - mae: 1.2793\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8611 - mae: 1.2508\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8586 - mae: 1.2459\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8484 - mae: 1.2337\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8480 - mae: 1.2334\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8450 - mae: 1.2400\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8413 - mae: 1.2310\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8416 - mae: 1.2242\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8463 - mae: 1.2295\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8315 - mae: 1.2140\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8310 - mae: 1.2129\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8321 - mae: 1.2138\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8216 - mae: 1.2037\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8291 - mae: 1.2311\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8262 - mae: 1.2259\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8147 - mae: 1.1981\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8385 - mae: 1.2065\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8094 - mae: 1.1807\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8263 - mae: 1.2335\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8267 - mae: 1.2420\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8229 - mae: 1.1989\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8192 - mae: 1.1924\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8059 - mae: 1.1976\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8048 - mae: 1.2079\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7953 - mae: 1.1751\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7956 - mae: 1.1712\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7921 - mae: 1.1682\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7892 - mae: 1.1732\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7895 - mae: 1.1779\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7874 - mae: 1.1684\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7834 - mae: 1.1635\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7809 - mae: 1.1592\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7795 - mae: 1.1595\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7768 - mae: 1.1567\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7743 - mae: 1.1504\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7754 - mae: 1.1572\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7708 - mae: 1.1528\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7716 - mae: 1.1500\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7722 - mae: 1.1459\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7727 - mae: 1.1415\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7617 - mae: 1.1451\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7739 - mae: 1.1783\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7703 - mae: 1.1573\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7595 - mae: 1.1300\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7605 - mae: 1.1461\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7546 - mae: 1.1383\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7504 - mae: 1.1280\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7489 - mae: 1.1243\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7499 - mae: 1.1246\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7466 - mae: 1.1239\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7525 - mae: 1.1259\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7423 - mae: 1.1159\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7410 - mae: 1.1184\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7447 - mae: 1.1388\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7442 - mae: 1.1246\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7378 - mae: 1.1056\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7379 - mae: 1.1157\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7333 - mae: 1.1097\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7299 - mae: 1.1015\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7282 - mae: 1.1008\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7251 - mae: 1.0993\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7251 - mae: 1.1095\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7241 - mae: 1.1017\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7219 - mae: 1.0929\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7187 - mae: 1.0894\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7244 - mae: 1.1144\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7202 - mae: 1.1049\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7154 - mae: 1.0840\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7128 - mae: 1.0825\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1215560051 T005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_42424\\1929561199.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Status = Status.append({'SKU':producto, 'Tienda':tienda, 'loss':loss, 'mae':mae}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 5s 20ms/step - loss: 19.0661 - mae: 19.5544\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 15.8295 - mae: 16.3206\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 11.0533 - mae: 11.5500\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.7041 - mae: 8.1925\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.4568 - mae: 7.9493\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 8.4653 - mae: 8.9568\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.5087 - mae: 9.0034\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.7415 - mae: 7.2185\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 5.1384 - mae: 5.6349\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.5760 - mae: 5.0734\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.5584 - mae: 5.0370\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.6910 - mae: 4.1657\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.5827 - mae: 3.0358\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2635 - mae: 2.7471\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8954 - mae: 2.3511\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2894 - mae: 1.7088\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3754 - mae: 1.8129\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3192 - mae: 1.7589\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3934 - mae: 1.8614\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4357 - mae: 1.8825\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3159 - mae: 1.7601\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2656 - mae: 1.7194\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2067 - mae: 1.6705\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1707 - mae: 1.6231\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1561 - mae: 1.6035\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1510 - mae: 1.5875\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1643 - mae: 1.5950\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1594 - mae: 1.5933\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1157 - mae: 1.5510\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1051 - mae: 1.5369\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1208 - mae: 1.5644\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0763 - mae: 1.5163\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0762 - mae: 1.5096\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0556 - mae: 1.4985\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0940 - mae: 1.5298\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0348 - mae: 1.4819\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0987 - mae: 1.5258\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0490 - mae: 1.4828\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0377 - mae: 1.4781\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0450 - mae: 1.4802\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0311 - mae: 1.4724\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0330 - mae: 1.4635\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0065 - mae: 1.4400\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0059 - mae: 1.4417\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9862 - mae: 1.4142\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0168 - mae: 1.4337\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9953 - mae: 1.4127\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9752 - mae: 1.3951\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9873 - mae: 1.4061\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9892 - mae: 1.4002\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9635 - mae: 1.3772\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9859 - mae: 1.3959\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9612 - mae: 1.3691\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9865 - mae: 1.4059\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9688 - mae: 1.3825\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9659 - mae: 1.3735\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9420 - mae: 1.3551\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9691 - mae: 1.3837\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9658 - mae: 1.3779\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9523 - mae: 1.3599\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9422 - mae: 1.3532\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9433 - mae: 1.3552\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9318 - mae: 1.3338\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9471 - mae: 1.3477\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9302 - mae: 1.3344\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9381 - mae: 1.3492\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9263 - mae: 1.3264\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9266 - mae: 1.3285\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9653 - mae: 1.3768\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9374 - mae: 1.3426\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9392 - mae: 1.3414\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9252 - mae: 1.3249\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9165 - mae: 1.3204\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9558 - mae: 1.3610\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9127 - mae: 1.3143\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9650 - mae: 1.3615\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9195 - mae: 1.2994\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9950 - mae: 1.4006\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9323 - mae: 1.3203\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9527 - mae: 1.3502\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9328 - mae: 1.3400\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9193 - mae: 1.3214\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9109 - mae: 1.3077\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9186 - mae: 1.3196\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9152 - mae: 1.3093\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9336 - mae: 1.3260\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9092 - mae: 1.3066\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9074 - mae: 1.3068\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9154 - mae: 1.3141\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9078 - mae: 1.3083\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9258 - mae: 1.3290\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9060 - mae: 1.2995\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9085 - mae: 1.3086\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8955 - mae: 1.2913\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9161 - mae: 1.3063\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9008 - mae: 1.2826\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9329 - mae: 1.3362\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9039 - mae: 1.2996\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9143 - mae: 1.3052\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8983 - mae: 1.2876\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1215560051 T006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcolin\\AppData\\Local\\Temp\\ipykernel_42424\\1929561199.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Status = Status.append({'SKU':producto, 'Tienda':tienda, 'loss':loss, 'mae':mae}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fcolin\\Documents\\DataScience - Merchandaising\\BuffersBasicosV1\\code\\Pruebas.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m df_inv_ventas_hist[df_inv_ventas_hist[\u001b[39m'\u001b[39m\u001b[39mSKU\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m producto]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m tienda \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mLocation Code\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     bd, loss, mae \u001b[39m=\u001b[39m proyeccion_RNN(producto, tienda)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     Proyecciones \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([Proyecciones, bd], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     Status \u001b[39m=\u001b[39m Status\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mSKU\u001b[39m\u001b[39m'\u001b[39m:producto, \u001b[39m'\u001b[39m\u001b[39mTienda\u001b[39m\u001b[39m'\u001b[39m:tienda, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m:loss, \u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m:mae}, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\fcolin\\Documents\\DataScience - Merchandaising\\BuffersBasicosV1\\code\\Pruebas.ipynb Cell 9\u001b[0m in \u001b[0;36mproyeccion_RNN\u001b[1;34m(producto, tienda)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9), metrics=[\"accuracy\"])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mHuber(), optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset,epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m'''forecast = []\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor time in range(len(series) - window_size):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m#print(tf.keras.metrics.mean_squared_error(x_valid, results).numpy())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m#print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fcolin/Documents/DataScience%20-%20Merchandaising/BuffersBasicosV1/code/Pruebas.ipynb#X11sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m ultima_fecha \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(df\u001b[39m.\u001b[39mloc[(\u001b[39mlen\u001b[39m(df)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m])[:\u001b[39m10\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2630\u001b[0m         args,\n\u001b[0;32m   2631\u001b[0m         kwargs,\n\u001b[0;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1116\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1117\u001b[0m       original_func,\n\u001b[0;32m   1118\u001b[0m       args,\n\u001b[0;32m   1119\u001b[0m       kwargs,\n\u001b[0;32m   1120\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1121\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1122\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1123\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1124\u001b[0m       ))\n\u001b[0;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5wvjf68_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1041\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1031\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:893\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    892\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    894\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m   \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[39m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    538\u001b[0m       loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    539\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:590\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    588\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(tape, loss, var_list, grad_loss)\n\u001b[0;32m    592\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes([\n\u001b[0;32m    593\u001b[0m     v \u001b[39mfor\u001b[39;00m g, v \u001b[39min\u001b[39;00m grads_and_vars\n\u001b[0;32m    594\u001b[0m     \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m v\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m tf\u001b[39m.\u001b[39mresource\n\u001b[0;32m    595\u001b[0m ])\n\u001b[0;32m    597\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:471\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    470\u001b[0m   \u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m   grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    472\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:750\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._backward.<locals>._backward_function\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward_function\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m    749\u001b[0m   call_op \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mop\n\u001b[1;32m--> 750\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rewrite_forward_and_call_backward(call_op, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:666\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._rewrite_forward_and_call_backward\u001b[1;34m(self, op, *doutputs)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rewrite_forward_and_call_backward\u001b[39m(\u001b[39mself\u001b[39m, op, \u001b[39m*\u001b[39mdoutputs):\n\u001b[0;32m    665\u001b[0m   \u001b[39m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m   forward_function, backwards_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_backward(\u001b[39mlen\u001b[39;49m(doutputs))\n\u001b[0;32m    667\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m backwards_function\u001b[39m.\u001b[39moutputs:\n\u001b[0;32m    668\u001b[0m     \u001b[39mreturn\u001b[39;00m backwards_function\u001b[39m.\u001b[39mstructured_outputs\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:599\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39mif\u001b[39;00m forward_backward \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m forward_backward\n\u001b[1;32m--> 599\u001b[0m forward, backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_forward_backward(num_doutputs)\n\u001b[0;32m    600\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs[num_doutputs] \u001b[39m=\u001b[39m (forward, backward)\n\u001b[0;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m forward, backward\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:642\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m    640\u001b[0m   backwards_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mFuncGraph(\n\u001b[0;32m    641\u001b[0m       _backward_name(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mname))\n\u001b[1;32m--> 642\u001b[0m   func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    643\u001b[0m       name\u001b[39m=\u001b[39;49mbackwards_graph\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    644\u001b[0m       python_func\u001b[39m=\u001b[39;49m_backprop_function,\n\u001b[0;32m    645\u001b[0m       args\u001b[39m=\u001b[39;49m[], kwargs\u001b[39m=\u001b[39;49m{},\n\u001b[0;32m    646\u001b[0m       signature\u001b[39m=\u001b[39;49msignature,\n\u001b[0;32m    647\u001b[0m       func_graph\u001b[39m=\u001b[39;49mbackwards_graph)\n\u001b[0;32m    648\u001b[0m   backwards_graph_captures \u001b[39m=\u001b[39m backwards_graph\u001b[39m.\u001b[39mexternal_captures\n\u001b[0;32m    649\u001b[0m   captures_from_forward \u001b[39m=\u001b[39m [\n\u001b[0;32m    650\u001b[0m       c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m backwards_graph_captures \u001b[39mif\u001b[39;00m\n\u001b[0;32m    651\u001b[0m       \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(c, ops\u001b[39m.\u001b[39mEagerTensor) \u001b[39mand\u001b[39;00m c\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph]\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:633\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward.<locals>._backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backprop_function\u001b[39m(\u001b[39m*\u001b[39mgrad_ys):\n\u001b[0;32m    632\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 633\u001b[0m     \u001b[39mreturn\u001b[39;00m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    634\u001b[0m         trainable_outputs,\n\u001b[0;32m    635\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49minputs,\n\u001b[0;32m    636\u001b[0m         grad_ys\u001b[39m=\u001b[39;49mgrad_ys,\n\u001b[0;32m    637\u001b[0m         src_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:554\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    552\u001b[0m from_ops \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mop \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m xs]\n\u001b[0;32m    553\u001b[0m stop_gradient_ops \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mop \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m stop_gradients]\n\u001b[1;32m--> 554\u001b[0m reachable_to_ops, pending_count, loop_state \u001b[39m=\u001b[39m _PendingCount(\n\u001b[0;32m    555\u001b[0m     to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs_set)\n\u001b[0;32m    557\u001b[0m \u001b[39m# Iterate over the collected ops.\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m# grads: op => list of gradients received on each output endpoint of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m# aggregate the list of received gradients into a Add() Operation if there\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# is more than one.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m grads \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:120\u001b[0m, in \u001b[0;36m_PendingCount\u001b[1;34m(to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs_set)\u001b[0m\n\u001b[0;32m    115\u001b[0m       queue\u001b[39m.\u001b[39mappend(inp\u001b[39m.\u001b[39mop)\n\u001b[0;32m    116\u001b[0m \u001b[39m# X in between_ops iff X is on a path of zero or more backpropagatable tensors\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m# between from_ops and to_ops\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39m# 'loop_state' is None if there are no while loops.\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m loop_state \u001b[39m=\u001b[39m control_flow_state\u001b[39m.\u001b[39;49mMaybeCreateControlFlowState(\n\u001b[0;32m    121\u001b[0m     between_op_list, between_ops, colocate_gradients_with_ops)\n\u001b[0;32m    123\u001b[0m \u001b[39m# Initialize pending count for between ops.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m pending_count \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mdefaultdict(\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_state.py:769\u001b[0m, in \u001b[0;36mMaybeCreateControlFlowState\u001b[1;34m(between_op_list, between_ops, colocate_gradients_with_ops)\u001b[0m\n\u001b[0;32m    767\u001b[0m loop_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m between_op_list:\n\u001b[1;32m--> 769\u001b[0m   \u001b[39mif\u001b[39;00m util\u001b[39m.\u001b[39;49mIsLoopExit(op):\n\u001b[0;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m loop_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m       loop_state \u001b[39m=\u001b[39m _ControlFlowState()\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_util.py:105\u001b[0m, in \u001b[0;36mIsLoopExit\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIsLoopExit\u001b[39m(op):\n\u001b[0;32m    104\u001b[0m   \u001b[39m\"\"\"Return true if `op` is an Exit.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m   \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mExit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m op\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRefExit\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fcolin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2541\u001b[0m, in \u001b[0;36mOperation.type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   2539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2540\u001b[0m   \u001b[39m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2541\u001b[0m   \u001b[39mreturn\u001b[39;00m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationOpType(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Proyecciones = pd.DataFrame(columns=['SKU', 'Tienda', 'Fecha', 'Proyeccion'])\n",
    "Status = pd.DataFrame(columns=['SKU', 'Tienda', 'loss', 'mae'])\n",
    "\n",
    "for producto in df_inv_ventas_hist['SKU'].unique():\n",
    "    df = df_inv_ventas_hist[df_inv_ventas_hist['SKU'] == producto]\n",
    "    for tienda in df['Location Code'].unique():\n",
    "        bd, loss, mae = proyeccion_RNN(producto, tienda)\n",
    "        Proyecciones = pd.concat([Proyecciones, bd], axis=0)\n",
    "        Status = Status.append({'SKU':producto, 'Tienda':tienda, 'loss':loss, 'mae':mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Tienda</th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1215560051</td>\n",
       "      <td>E002</td>\n",
       "      <td>0.749583</td>\n",
       "      <td>1.160705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1215560051</td>\n",
       "      <td>T001</td>\n",
       "      <td>1.130049</td>\n",
       "      <td>1.572009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215560051</td>\n",
       "      <td>T003</td>\n",
       "      <td>0.629425</td>\n",
       "      <td>1.061737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1215560051</td>\n",
       "      <td>T004</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>1.082541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1215560051</td>\n",
       "      <td>T005</td>\n",
       "      <td>0.898344</td>\n",
       "      <td>1.287563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SKU Tienda      loss       mae\n",
       "0  1215560051   E002  0.749583  1.160705\n",
       "1  1215560051   T001  1.130049  1.572009\n",
       "2  1215560051   T003  0.629425  1.061737\n",
       "3  1215560051   T004  0.712766  1.082541\n",
       "4  1215560051   T005  0.898344  1.287563"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Status.to_csv('Status.csv', index=False)\n",
    "Proyecciones.to_csv('Proyecciones.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d8efc0accedf8a71318180958b2a2c3ace073b5a0267b0b56f49dfe74d51c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
