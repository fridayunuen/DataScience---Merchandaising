{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffers Basicos\n",
      "Fecha: 2023-02-08    Semana: 06\n",
      "En: [Division Code] = 'BEAUTY'\n",
      "Consultando inventario actual... \n",
      "Consultando clones... \n",
      "Concateando proyecciones RNN... \n",
      "Consultando On Order...\n",
      "Consultando matrices y res lean...\n",
      "Obteniendo el buffer actual.... \n",
      "Archivo de buffers por tiendas y resumen generados con exito en la carpeta de output S:\\BI\\3. MERCHANDISING\\FRAMEWORK\\FRAMEWORK\\ZIMA\\BuffersBasicosV1\\output\n"
     ]
    }
   ],
   "source": [
    "BU=input('''Selecciona la BU: BEAUTY JEW ACC CALZADO ROPA ''') \n",
    "\n",
    "#def CreateProyeccionActual(BU):\n",
    "\n",
    "div =   {'BEAUTY': \"[Division Code] = 'BEAUTY'\", \n",
    "            'JEW': \"[Division Code] IN ('W-JEW', 'M-JEW')\",\n",
    "            'ACC': \"[Division Code] IN ('W-ACC', 'M-ACC')\",\n",
    "        'CALZADO':\"[Division Code] in ('W-SHO','M-SHO')\",\n",
    "           'ROPA':\"[Division Code] in ('W-CLO','M-CLO')\"} \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# Credenciales de SQL Server\n",
    "with open('Credenciales.json') as f:\n",
    "   credenciales = json.load(f)\n",
    "\n",
    "today = datetime.date.today()\n",
    "#today = datetime.date(2023, 2, 10)\n",
    "end_date = str(today)\n",
    "fecha_analizada = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "print('Buffers Basicos')\n",
    "print(\"Fecha: \" +end_date +\"    Semana: \"+fecha_analizada.strftime(\"%V\"))\n",
    "print(\"En: \"+str(div[BU]))\n",
    "\n",
    "week_actual = str(int(str(fecha_analizada.strftime(\"%V\")))-1)\n",
    "WK2 = \"'\"+ week_actual +\"'\"\n",
    "YEAR_ACTUAL = str(fecha_analizada.year)\n",
    "\n",
    "carpeta_input = R'S:\\BI\\3. MERCHANDISING\\FRAMEWORK\\FRAMEWORK\\ZIMA\\BuffersBasicosV1\\input'\n",
    "carpeta_output = R'S:\\BI\\3. MERCHANDISING\\FRAMEWORK\\FRAMEWORK\\ZIMA\\BuffersBasicosV1\\output'\n",
    "\n",
    "# Consultando predicción actual (método con el que se calcula actuaqlmente ), esta se realiza cada semana-----------------\n",
    "df_producto_tienda = os.path.join(carpeta_output, 'df_producto_tienda_'+BU+'.csv')\n",
    "df_producto_tienda = pd.read_csv(df_producto_tienda)\n",
    "df_producto_tienda['SKU'] = df_producto_tienda['SKU'].astype(str)\n",
    "\n",
    "\n",
    "# Conexion SQL Server--------------------------------------------------------------------------------------\n",
    "connection_string = 'DRIVER={SQL Server};SERVER=Shjet-prod;DATABASE=Allocations;UID='+ credenciales['usuario'] +';PWD='+credenciales['password']\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "engine = create_engine(connection_url)\n",
    "conn = engine.connect()\n",
    "\n",
    "# Agregando el inventario actual -------------------------------------------\n",
    "print('Consultando inventario actual... ')\n",
    "\n",
    "query_inventarioActual = '''\n",
    "\t\tSELECT CONCAT(   SUBSTRING(CONCAT([Item No_], [VariantColor]),1,10) , [Location Code]) AS [ID]\n",
    "\t\t\t,CAST(SUM([Inventario]) AS INT) AS [Inventario_Actual]\n",
    "\t\t\n",
    "\t\tFROM PadresClones_Basicos AS pcb\n",
    "\t\tJOIN  [Flash_BC].[dbo].[InvHistBC] AS inv\n",
    "\t\tON SUBSTRING(CONCAT(inv.[Item No_], inv.[VariantColor]),1,10) = pcb.VarianteColor\n",
    "\n",
    "\n",
    "\t\tWHERE '''+ str(div[BU]) +'''\n",
    "\t\t\t\n",
    "\t\t\tAND [WK] = '''+str(WK2)+'''\n",
    "\t\t\t\n",
    "\t\t\tAND [year] = '''+str(YEAR_ACTUAL)+'''\n",
    "\t\t\t\n",
    "\t\t\t-- Seleccionando solo Tiendas y E002\n",
    "\t\t\tAND (SUBSTRING([Location Code], 1, 1) = 'E' \n",
    "\t\t\t\t\t\tOR\t\n",
    "\t\t\t\tSUBSTRING([Location Code], 1, 1) = 'T')\n",
    "\n",
    "\t\tGROUP BY CONCAT(SUBSTRING(CONCAT([Item No_], [VariantColor]),1,10), [Location Code])\n",
    "\t'''\n",
    "\n",
    "df_inventarioActual = pd.read_sql(query_inventarioActual, con=conn)\n",
    "\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, df_inventarioActual, on='ID', how='left')\n",
    "df_producto_tienda['Inventario_Actual'] = df_producto_tienda['Inventario_Actual'].fillna(0)\n",
    "\n",
    "if len(df_producto_tienda[df_producto_tienda['Proyeccion_Actual'].isna()]) >0:\n",
    "    print('Faltan datos para realizar la proyeccion actual, son sustituidos por 0')\n",
    "    df_producto_tienda['Proyeccion_Actual'] = df_producto_tienda['Proyeccion_Actual'].fillna(0)\n",
    "\n",
    "# Este es un input\n",
    "Minimos_Maximos = pd.read_excel(os.path.join(carpeta_input, \"Minimos_Maximos.xlsx\"), dtype=str)\n",
    "Minimos_Maximos[\"SKU\"] = Minimos_Maximos[\"Original_Vendor_Item_No\"].astype(str) + Minimos_Maximos[\"Code_Color\"].astype(str)\n",
    "Minimos_Maximos = Minimos_Maximos[[\"SKU\", \"Multiplo_Distribucion\",\"Minimo_Tienda\", \"Maximo_Tienda\"]]\n",
    "Minimos_Maximos[['Multiplo_Distribucion', 'Minimo_Tienda', 'Maximo_Tienda']] = Minimos_Maximos[['Multiplo_Distribucion', 'Minimo_Tienda', 'Maximo_Tienda']].astype(int)\n",
    "\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, Minimos_Maximos, on='SKU', how='left')\n",
    "\n",
    "print(\"Consultando clones... \")\n",
    "query_clones = '''\n",
    "SELECT \n",
    "\tSUBSTRING(CONCAT([Original Vendor Item No_], [Variant Code]), 1, 10) AS [SKU],\n",
    "\tIIF([No_] = '',\n",
    "\t\t\t\tSUBSTRING(CONCAT([Original Vendor Item No_], [Variant Code]), 1, 10),\n",
    "\t\t\t\tSUBSTRING(CONCAT([No_], [Variant Code]), 1, 10)\n",
    "\t\t\t\t) AS [No_], \n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\tpcb.[Division Code],\n",
    "\t\t\t\t\t\t[Description], \n",
    "\t\t\t\t\t\t[Product Group Code], \n",
    "\t\t\t\t\t\t[Item Category Code],\n",
    "\t\t\t\t\t\t[Weather]\n",
    "\t\t\t\t\n",
    "\tFROM   PadresClones_Basicos AS pcb\n",
    "\tJOIN [Allocations].[dbo].[Item_BC] \n",
    "\tON pcb.VarianteColor = SUBSTRING(CONCAT([No_], [Variant Code]), 1, 10)\n",
    "\n",
    "\tWHERE pcb.'''+ str(div[BU]) +'''\n",
    "\n",
    "\tORDER BY [SKU]\n",
    "\t'''\n",
    "\n",
    "df_clones = pd.read_sql_query(query_clones, conn)\n",
    "df_clones.drop_duplicates(subset =\"SKU\", keep = 'first', inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "data_tiendas = pd.read_excel(os.path.join(carpeta_input, \"DATOS DE TIENDAS PBI 221206.xlsx\"))\n",
    "# Agregando todos las caracterísiticas de la tienda ------------------------\n",
    "data_tiendas= data_tiendas[['NO', 'TIENDA', 'CLIMA', 'SH MAN', 'CANDY']]\n",
    "data_tiendas.columns = ['Location Code', 'Tienda', 'Clima', 'ShMan', 'Candy']\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, data_tiendas, on='Location Code', how='left')\n",
    "\n",
    "\n",
    "# Si hay dulces la cobertura es diferente por que son perecederos \n",
    "# 6 semanas y si es tienda hot 5 semanas\n",
    "if 'CANDY' in df_clones['Item Category Code'].unique():\n",
    "\n",
    "    print ('Existen dulces en la division')\n",
    "    condicion = df_clones[['SKU', 'Item Category Code']]\n",
    "    df_producto_tienda = pd.merge(df_producto_tienda, condicion, on='SKU', how='left')\n",
    "    \n",
    "    # Condiciones\n",
    "    df_producto_tienda.loc[df_producto_tienda['Item Category Code'] == 'CANDY', 'Cobertura'] = 6\n",
    "    df_producto_tienda.loc[(df_producto_tienda['Clima'] == 'HOT') & (df_producto_tienda['Item Category Code'] == 'CANDY'), 'Cobertura'] = 5\n",
    "    \n",
    "    df_producto_tienda.drop(columns=['Item Category Code'], inplace=True)\n",
    "\n",
    "\n",
    "# Calculo de buffer\n",
    "# Redondear a multiplo de distribución deja el multiplo mas cercano \n",
    "def roundBy(x, base, iferror):\n",
    "    try:\n",
    "        rnd = base*round(x/base)\n",
    "        return rnd\n",
    "    except:\n",
    "\n",
    "        return iferror\n",
    "# Regla creada por el equipo de merch \n",
    "def crear_nuevo_buffer(cobertura_ventas, minimo_tienda, maximo_tienda):\n",
    "    \n",
    "    if cobertura_ventas <= minimo_tienda:\n",
    "        cobertura_ventas = minimo_tienda\n",
    "\n",
    "    if cobertura_ventas > maximo_tienda:\n",
    "        cobertura_ventas = maximo_tienda \n",
    "    \n",
    "    return cobertura_ventas\n",
    "\n",
    "# Calculando buffer con el método actual\n",
    "df_producto_tienda[\"Cobertura_ventas\"] = df_producto_tienda.apply(lambda x: roundBy(x[\"Proyeccion_Actual\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "df_producto_tienda[\"Nuevo_Buffer\"] = df_producto_tienda.apply(lambda x: crear_nuevo_buffer(x[\"Cobertura_ventas\"], x[\"Minimo_Tienda\"], x[\"Maximo_Tienda\"]), axis=1)\n",
    "df_producto_tienda['Ventas_Suma'] = df_producto_tienda['Ventas_Suma'].astype(int)\n",
    "df_producto_tienda['Proyeccion_Actual'] = df_producto_tienda['Proyeccion_Actual'].astype(int)\n",
    "df_producto_tienda['Inventario_Actual'] = df_producto_tienda['Inventario_Actual'].astype(int)\n",
    "\n",
    "if df_producto_tienda['Multiplo_Distribucion'].isna().sum()>0: \n",
    "    print('ERROR: Existen productos sin información de Multiplo de distribución Minimos o Máximos')\n",
    "    print(df_producto_tienda[df_producto_tienda['Multiplo_Distribucion'].isna()]['SKU'].unique())\n",
    "    exit()\n",
    "\n",
    "df_producto_tienda['Nuevo_Buffer'] = df_producto_tienda['Nuevo_Buffer'].astype(int)\n",
    "\n",
    "\n",
    "# Prediccion RNN-----------------------------------------------------------\n",
    "\n",
    "proyecciones_path = os.path.join(carpeta_output, \"Proyecciones_\"+BU+\".csv\")\n",
    "proyecciones = pd.read_csv(proyecciones_path)\n",
    "\n",
    "proyecciones['SKU'] = proyecciones['SKU'].astype(str)\n",
    "proyecciones['ID'] = proyecciones['SKU'] + proyecciones['Tienda']\n",
    "\n",
    "print('Concateando proyecciones RNN... ')\n",
    "\n",
    "df_producto_tienda['Proyeccion_RNN'] = ''\n",
    "df_producto_tienda['Proyeccion_Tiempo'] = ''\n",
    "\n",
    "\n",
    "for id in df_producto_tienda['ID'].unique():\n",
    "\n",
    "    cobertura = df_producto_tienda.loc[df_producto_tienda['ID'] == id, 'Cobertura'].values[0]\n",
    "\n",
    "    if cobertura is not None or cobertura != 0  :\n",
    "        if id in proyecciones['ID'].unique():\n",
    "            proyeccion = proyecciones[proyecciones['ID'] == id].head(int(cobertura))\n",
    "            \n",
    "            inicio  = proyeccion['Fecha'].min()\n",
    "            fin = proyeccion['Fecha'].max()\n",
    "            df_producto_tienda.loc[df_producto_tienda['ID'] == id, 'Proyeccion_Tiempo'] = str(inicio) + ' : ' + str(fin)\n",
    "            \n",
    "            proyeccion = proyeccion[['ID', 'Proyeccion']].groupby('ID').sum().reset_index()\n",
    "            proyeccion.columns = ['ID', 'Proyeccion_RNN']\n",
    "            df_producto_tienda.loc[df_producto_tienda['ID'] == id, 'Proyeccion_RNN'] = proyeccion['Proyeccion_RNN'][0]\n",
    "    else:\n",
    "        df_producto_tienda.loc[df_producto_tienda['ID'] == id, 'Proyeccion_RNN'] = 0   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tal vez aqui podríamos dirigir las operaciones solo a los productos que tienen cobertura != ''\n",
    "df_producto_tienda['Proyeccion_RNN'] = df_producto_tienda['Proyeccion_RNN'].replace('', 0)\n",
    "df_producto_tienda['Proyeccion_RNN'] = df_producto_tienda['Proyeccion_RNN'].astype(int)\n",
    "df_producto_tienda[\"Cobertura_ventas_RNN\"] = df_producto_tienda.apply(lambda x: roundBy(x[\"Proyeccion_RNN\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "df_producto_tienda[\"Nuevo_Buffer_RNN\"] = df_producto_tienda.apply(lambda x: crear_nuevo_buffer(x[\"Cobertura_ventas_RNN\"], x[\"Minimo_Tienda\"], x[\"Maximo_Tienda\"]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#df = df_producto_tienda\n",
    "#df.columns\n",
    "#df = df[['ID', 'Proyeccion_RNN', 'Proyeccion_Actual']]\n",
    "\n",
    "#df['Proyeccion_RNN'] = df['Proyeccion_RNN'].replace(np.nan, 0)\n",
    "#df['Proyeccion_RNN'] = df['Proyeccion_RNN'].replace(np.nan, 0)\n",
    "\n",
    "# si el procentafe de diferencia entre proyecciones es mayor a 200% se coloca np.nan\n",
    "# tratar de aplicarlo a la columna Proyeccion_RNN contemplando que existen 0 en la columna Proyeccion_Actual\n",
    "#df['Proyeccion_RNN'] = df.apply(lambda x:  np.nan if (x['Proyeccion_RNN'] / x['Proyeccion_Actual']) > 2 else x['Proyeccion_RNN'], axis=1)\n",
    "\n",
    "df_producto_tienda.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in df_producto_tienda.index:\n",
    "    if df_producto_tienda.loc[i, 'Proyeccion_Actual'] != 0:\n",
    "        df_producto_tienda.loc[i, 'Proyeccion_RNN'] = np.nan if (df_producto_tienda.loc[i, 'Proyeccion_RNN'] / df_producto_tienda.loc[i, 'Proyeccion_Actual']) > 3 else df_producto_tienda.loc[i, 'Proyeccion_RNN']\n",
    "    else: \n",
    "        df_producto_tienda.loc[i, 'Proyeccion_RNN'] = np.nan\n",
    "\n",
    "\n",
    "df_producto_tienda.sort_values(by=['Proyeccion_RNN'], inplace=True, ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_producto_tienda.loc[df_producto_tienda['Proyeccion_RNN'] == 1000000, ['Proyeccion_RNN',\"Cobertura_ventas_RNN\", 'Nuevo_Buffer_RNN']] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Agregando caracteristicas producto ---------------------------------------\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, df_clones, on='SKU', how='left')\n",
    "\n",
    "\n",
    "# ON ORDER ----------------------------------------------------------------------------------\n",
    "end_date = str(today )\n",
    "end_date = \"'\"+end_date+\"'\"\n",
    "\n",
    "# llegará mercancia durante el tiempo de cobertura? \n",
    "\n",
    "cobertura_onorder = str(today +  pd.DateOffset(days=8*7))\n",
    "cobertura_onorder = cobertura_onorder.replace(\" 00:00:00\",\"\")\n",
    "cobertura_onorder = \"'\"+cobertura_onorder+\"'\"\n",
    "\n",
    "\n",
    "print('Consultando On Order...')\n",
    "\n",
    "query_onOrder = '''\n",
    "    SELECT [VarianteColor] AS [No_], [Qtty Pen] AS [Qtty Pen], [Expected Receipt Week], [Expected Receipt Year]\n",
    "    FROM [Allocations].[dbo].[PadresClones_Basicos] AS pcb\n",
    "    JOIN SH_REPORTS.dbo.SH_OnOrderBC_vw as OnOrder\n",
    "    ON pcb.VarianteColor = SUBSTRING( CONCAT([Item], [Variant Code]),1,10)\n",
    "    WHERE  pcb.'''+ str(div[BU]) +'''\n",
    "    AND [Expected Receipt Date] BETWEEN '''+end_date+''' AND '''+cobertura_onorder+'''\n",
    "    AND [Qtty Pen] IS NOT NULL\n",
    "    --- GROUP BY [VarianteColor]\n",
    "\n",
    "'''\n",
    "df_onorder = pd.read_sql(query_onOrder, con=conn)\n",
    "\n",
    "df_onorder['week-year'] = df_onorder['Expected Receipt Week'].astype(str) +' - ' + df_onorder['Expected Receipt Year'].astype(str)\n",
    "df_onorder = df_onorder[['No_', 'Qtty Pen', 'week-year']]\n",
    "df_onorder = pd.merge(df_clones, df_onorder,on='No_', how='left')\n",
    "df_onorder['Qtty Pen'] = df_onorder['Qtty Pen'].fillna(0)\n",
    "\n",
    "df_onorder = df_onorder[['SKU', 'Qtty Pen','week-year']]\n",
    "# agrupar por sku y week-year, sumar qtty pen\n",
    "df_onorder = df_onorder.groupby(['SKU', 'week-year']).sum().reset_index()\n",
    "\n",
    "#week-year as a column\n",
    "df_onorder = df_onorder.pivot(index='SKU', columns='week-year', values='Qtty Pen').reset_index()\n",
    "# sum rows\n",
    "\n",
    "qtty_total = df_onorder.set_index('SKU')\n",
    "qtty_total = qtty_total.sum(axis=1).reset_index()\n",
    "qtty_total.columns = ['SKU', 'QttyPen']\n",
    "df_onorder = pd.merge(qtty_total, df_onorder, on='SKU', how='left')\n",
    "\n",
    "\n",
    "#df_onorder['Qtty_Pen'] = df_onorder.sum(axis=1)\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, df_onorder, on='SKU', how='left')\n",
    "\n",
    "# MATRIX paa poder jalar REST LEAN ----------------------------------------------------------------------------------\n",
    "print('Consultando matrices y res lean...')\n",
    "query_matrix = '''\n",
    "SELECT \n",
    "       [Product Group Code] COLLATE SQL_Latin1_General_CP1_CI_AS AS [Product Group Code],\n",
    "       [Matriz] COLLATE SQL_Latin1_General_CP1_CI_AS AS [Matriz]   \n",
    "      \n",
    "  FROM [Allocations].[dbo].[Matrix]\n",
    "  '''\n",
    "\n",
    "df_matrix = pd.read_sql(query_matrix, con=conn)\n",
    "matrix = pd.read_excel(r\"S:\\\\BI\\\\3. MERCHANDISING\\\\FRAMEWORK\\\\FRAMEWORK\\\\ZIMA\\\\Tabla Matrices.xlsx\",skiprows = 1)\n",
    "matrix = matrix[matrix[\"TIPO DE RESURTIDO\"] == \"RES LEAN\"]\n",
    "matrix = matrix[[\"MATRIZ\", \"MAX\"]]\n",
    "matrix.columns = [\"Matriz\", \"RES_LEAN\"]\n",
    "\n",
    "df_matrix = pd.merge(df_matrix, matrix, on='Matriz', how='left')\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, df_matrix, on='Product Group Code', how='left')\n",
    "\n",
    "# Obteniendo el buffer actual ----------------------------------------------------------------------------------\n",
    "def get_bufferanterior(file_excel):\n",
    "        \n",
    "    col_names =  []\n",
    "    for i in range(len(file_excel.iloc[:,0].values)):\n",
    "        if file_excel.iloc[i,0]==\"Location Code\":\n",
    "            index = i\n",
    "            break\n",
    "    col_names = file_excel.iloc[index].values\n",
    "    col_names = [x.replace('B-','') for x in col_names]\n",
    "    file_excel = file_excel.iloc[index+1:]\n",
    "    file_excel.columns = col_names\n",
    "    file_excel = file_excel.reset_index(drop=True)\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"Location Code\", \"SKU\", \"Buffer Actual\"])\n",
    "\n",
    "    # Estoy segura de que hay una forma más elegante de hacer esto, pero no la encontré se puede mejorar, mientras tanto, usamos un ciclo for\n",
    "    items = file_excel.loc[:,\"-\":].columns\n",
    "    items = items[1:]\n",
    "    items = [x for x in items if str(x) != '']\n",
    "    # delete everything not numeric value \n",
    "    items = [x for x in items if str(x).isnumeric()]\n",
    "    # drop duplicates\n",
    "    items = list(dict.fromkeys(items))\n",
    "\n",
    "    # Si hay columnas duplicadas se eliminan directamente, deberiamos validarlo? \n",
    "    file_excel = file_excel.loc[:,~file_excel.columns.duplicated()]\n",
    "\n",
    "    for item in items:\n",
    "\n",
    "        SKU = [item] * len(file_excel[\"Location Code\"])\n",
    "        Loc = file_excel[\"Location Code\"].values\n",
    "        df1 = pd.DataFrame({\"Location Code\": Loc, \"SKU\": SKU})\n",
    "        df1[\"Buffer Actual\"] = file_excel[item].values\n",
    "        df = pd.concat([df, df1])\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    df[\"ID\"] = df[\"SKU\"] + df[\"Location Code\"] \n",
    "    df = df[[\"ID\", \"Buffer Actual\"]]\n",
    "    df[\"Buffer Actual\"] = df[\"Buffer Actual\"].fillna(0)\n",
    "    df[\"Buffer Actual\"] = df[\"Buffer Actual\"].apply(lambda x: int(x))\n",
    "    df[\"Buffer Actual\"] = df[\"Buffer Actual\"].apply(lambda x: round(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Obteniendo el buffer actual.... ')\n",
    "if BU == 'BEAUTY' or BU == 'JEW' or BU == 'ACC':\n",
    "    acces = pd.read_excel(\"S:/BI/3. MERCHANDISING/FRAMEWORK/FRAMEWORK/ZIMA/Framework de Tiendas 2.0.xlsx\", sheet_name='BASICOS ACCESORIOS')\n",
    "    df_buffers = get_bufferanterior(acces)\n",
    "   \n",
    "if BU == \"ROPA\":\n",
    "    dama = pd.read_excel(\"S:/BI/3. MERCHANDISING/FRAMEWORK/FRAMEWORK/ZIMA/Framework de Tiendas 2.0.xlsx\", sheet_name='BASICOS DAMA')\n",
    "    man = pd.read_excel(\"S:/BI/3. MERCHANDISING/FRAMEWORK/FRAMEWORK/ZIMA/Framework de Tiendas 2.0.xlsx\", sheet_name='BASICOS MAN')\n",
    "    df_buffers = pd.concat([get_bufferanterior(dama), get_bufferanterior(man)]).reset_index(drop=True)\n",
    "\n",
    "if BU == \"CALZADO\":\n",
    "    calzado = pd.read_excel(\"S:/BI/3. MERCHANDISING/FRAMEWORK/FRAMEWORK/ZIMA/Framework de Tiendas 2.0.xlsx\", sheet_name='BASICOS CALZADO')\n",
    "    df_buffers = get_bufferanterior(calzado)    \n",
    "\n",
    "df_producto_tienda = pd.merge(df_producto_tienda, df_buffers, on='ID', how='left')\n",
    "\n",
    "# KPI que utiliza merch --------------------------------------------------------------------------------------------------------------\n",
    "df_producto_tienda[\"Rotacion_Proyectada\"] = df_producto_tienda[\"Nuevo_Buffer\"]/ df_producto_tienda[\"Ventas_Promedio\"]\n",
    "df_producto_tienda[\"Rotacion_Proyectada\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_producto_tienda[\"WOS\"] = df_producto_tienda[\"Inventario_Actual\"] / df_producto_tienda[\"Ventas_Promedio\"]\n",
    "\n",
    "\n",
    "df_producto_tienda[[\"Multiplo_Distribucion\", \"Ventas_Promedio\", \"Cobertura\", \"Minimo_Tienda\", \"Maximo_Tienda\"]] = df_producto_tienda[[\"Multiplo_Distribucion\", \"Ventas_Promedio\", \"Cobertura\", \"Minimo_Tienda\", \"Maximo_Tienda\"]].astype(float)\n",
    "df_producto_tienda[\"Diferencia_Buffer\"] = df_producto_tienda[\"Nuevo_Buffer\"] - df_producto_tienda[\"Buffer Actual\"] \n",
    "df_producto_tienda[\"Diferencia_Buffer_Caja\"]  =  df_producto_tienda[\"Diferencia_Buffer\"] /df_producto_tienda[\"Multiplo_Distribucion\"]\n",
    "\n",
    "\n",
    "# Lo dejo por separado para consultar si merch propone una diferencia diferente a 10 cajas por BU\n",
    "if div[BU] == \"[Division Code] in ('W-CLO','M-CLO')\": \n",
    "    df_producto_tienda[\"Flag_CambioBuffer_Caja\"] = np.where(abs(df_producto_tienda[\"Diferencia_Buffer_Caja\"]) >= 10, \"Revisar\", \"Ok\")\n",
    "if div[BU] == \"[Division Code] = 'BEAUTY'\":\n",
    "    df_producto_tienda[\"Flag_CambioBuffer_Caja\"] = np.where(abs(df_producto_tienda[\"Diferencia_Buffer_Caja\"]) >= 10, \"Revisar\", \"Ok\")\n",
    "if div[BU] == \"[Division Code] IN ('W-JEW', 'M-JEW')\":\n",
    "    df_producto_tienda[\"Flag_CambioBuffer_Caja\"] = np.where(abs(df_producto_tienda[\"Diferencia_Buffer_Caja\"]) >= 10, \"Revisar\", \"Ok\")\n",
    "if div[BU] == \"[Division Code] in ('W-SHO','M-SHO')\":\n",
    "    df_producto_tienda[\"Flag_CambioBuffer_Caja\"] = np.where(abs(df_producto_tienda[\"Diferencia_Buffer_Caja\"]) >= 10, \"Revisar\", \"Ok\")\n",
    "if div[BU] == \"[Division Code] IN ('W-ACC', 'M-ACC')\":\n",
    "    df_producto_tienda[\"Flag_CambioBuffer_Caja\"] = np.where(abs(df_producto_tienda[\"Diferencia_Buffer_Caja\"]) >= 10, \"Revisar\", \"Ok\")\n",
    "\n",
    "\n",
    "\n",
    "# Resumen --------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# El resuemn incluye los productos agrupados por SKU, ya no hay desglose por tienda\n",
    "resumen= df_producto_tienda[['SKU', 'Ventas_Suma','Proyeccion_RNN','Proyeccion_Actual', 'Inventario_Actual', \"Nuevo_Buffer\", \"Nuevo_Buffer_RNN\"]]\n",
    "#resumen= df_producto_tienda[['SKU', 'Ventas_Suma','Proyeccion_Actual', 'Inventario_Actual', \"Nuevo_Buffer\"]]\n",
    "resumen = resumen.groupby('SKU').sum().reset_index()\n",
    "\n",
    "resumen = pd.merge(resumen, df_clones, on='SKU', how='left')\n",
    "resumen = pd.merge(resumen, df_onorder, on='SKU', how='left')\n",
    "resumen = pd.merge(resumen, df_matrix, on='Product Group Code', how='left')\n",
    "\n",
    "df_buffers['SKU'] = df_buffers['ID'].str[0:10]\n",
    "df_buffers_resumen = df_buffers.groupby('SKU')['Buffer Actual'].sum().reset_index()\n",
    "resumen = pd.merge(resumen, df_buffers_resumen, on='SKU', how='left')\n",
    "\n",
    "# Agregando on order\n",
    "#resumen = pd.merge(resumen, df_onorder, on='SKU', how='left')\n",
    "\n",
    "#Buffer básico --------------------------------------------------------------------------------------------------------------------------------\n",
    "'''BUFFER DINAMICO''' #RECORDAR MANTENER ESTE BLOQUE EN FUTURAS VERSIONES\n",
    "'''import math\n",
    "#Funciones\n",
    "def condiciones(INV_BUFFER):\n",
    "    cond_superior = 66\n",
    "    cond_inferior = 33\n",
    "    if INV_BUFFER > cond_superior:\n",
    "        return 'BUFFER ALTO'\n",
    "    elif INV_BUFFER < cond_inferior:\n",
    "        return 'BUFFER BAJO'\n",
    "    else:\n",
    "        return 'BUFFER OK'\n",
    "\n",
    "def sigmoid(df):    \n",
    "    rango = 1.3\n",
    "    aceleracion = 4.9\n",
    "    cruce = 0.6\n",
    "    return rango*(1-1/(1+math.exp(-aceleracion*((df['INV_BUFFER']/100)-cruce))))-rango/2\n",
    "\n",
    "def redondear(numero, multiplo):\n",
    "    return round(numero / multiplo) * multiplo'''\n",
    "\n",
    "\n",
    "import BufferDinamico as bd\n",
    "\n",
    "df_producto_tienda[['INV_BUFFER', 'Nota_Buffer', 'Incremento_buffer', 'DB_Profundidad']] = ''\n",
    "df_producto_tienda['INV_BUFFER'], df_producto_tienda['Nota_Buffer'], df_producto_tienda['Incremento_buffer'], df_producto_tienda['DB_Profundidad'] = zip(*df_producto_tienda.apply(lambda x: bd.buffer_dinamico(x[\"Inventario_Actual\"],x[\"Nuevo_Buffer\"], x[\"Ventas_Suma\"]), axis=1))\n",
    "\n",
    "\n",
    "df_producto_tienda[['INV_BUFFER_RNN', 'Nota_Buffer_RNN', 'Incremento_buffer_RNN', 'DB_Profundidad_RNN']] = ''\n",
    "df_producto_tienda['INV_BUFFER_RNN'], df_producto_tienda['Nota_Buffer_RNN'], df_producto_tienda['Incremento_buffer_RNN'], df_producto_tienda['DB_Profundidad_RNN'] = zip(*df_producto_tienda.apply(lambda x: bd.buffer_dinamico(x[\"Inventario_Actual\"],x[\"Nuevo_Buffer_RNN\"], x[\"Ventas_Suma\"]), axis=1))\n",
    "df_producto_tienda[\"DB_Profundidad_RNN\"] = df_producto_tienda.apply(lambda x: roundBy(x[\"DB_Profundidad\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "\n",
    "df_producto_tienda.loc[df_producto_tienda['Proyeccion_RNN'] == 1000000, ['Proyeccion_RNN',\"Cobertura_ventas_RNN\", 'Nuevo_Buffer_RNN','INV_BUFFER_RNN', 'Nota_Buffer_RNN', 'Incremento_buffer_RNN', 'DB_Profundidad_RNN']] = np.nan\n",
    "\n",
    "    #DB_Profundidad = df_producto_tienda.apply(lambda x: roundBy(x[\"DB_Profundidad\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "\n",
    "#apply conditions #adaptar al nuevo input\n",
    "'''df_producto_tienda['INV_BUFFER'] = round(df_producto_tienda['Inventario_Actual'] / df_producto_tienda['Buffer Actual']*100,1)\n",
    "df_producto_tienda['WOS'] = round(df_producto_tienda['Inventario_Actual']/df_producto_tienda['Ventas_Suma'],1)\n",
    "df_producto_tienda['Nota_Buffer'] = df_producto_tienda['INV_BUFFER'].apply(condiciones)\n",
    "df_producto_tienda['Incremento_buffer'] = df_producto_tienda.apply(sigmoid, axis=1)\n",
    "df_producto_tienda['DB_Profundidad'] = df_producto_tienda['Buffer Actual']*(1+df_producto_tienda['Incremento_buffer'])\n",
    "df_producto_tienda['DB_Profundidad'] = df_producto_tienda['DB_Profundidad'].round(0)\n",
    "\n",
    "#FORMATO\n",
    "#CHANGE DE FORMAT OF COLUMNS 'INV_BUFFER' AND 'INCREMENTO_BUFFER' TO PERCENTAGE\n",
    "df_producto_tienda['INV_BUFFER'] = df_producto_tienda['INV_BUFFER'].astype(str) + '%'\n",
    "df_producto_tienda['Incremento_buffer'] = df_producto_tienda['Incremento_buffer'].astype(str) + '%'\n",
    "\n",
    "#round by with the function rounby the values in the column 'DB_Profundidad'\n",
    "df_producto_tienda[\"DB_Profundidad\"] = df_producto_tienda.apply(lambda x: roundBy(x[\"DB_Profundidad\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "'''\n",
    "\n",
    "'''df_producto_tienda['INV_BUFFER'] = round(df_producto_tienda['Inventario_Actual'] / df_producto_tienda['Nuevo_Buffer']*100,1)\n",
    "df_producto_tienda['WOS'] = round(df_producto_tienda['Inventario_Actual']/df_producto_tienda['Ventas_Suma'],1)\n",
    "df_producto_tienda['Nota_Buffer'] = df_producto_tienda['INV_BUFFER'].apply(condiciones)'''\n",
    "\n",
    "\n",
    "'''df_producto_tienda.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_producto_tienda['Incremento_buffer'] = ''\n",
    "for i in df_producto_tienda.index:\n",
    "    try:\n",
    "        df_producto_tienda['Incremento_buffer'][i] = condiciones(df_producto_tienda['INV_BUFFER'][i]) \n",
    "    except:\n",
    "        print(df_producto_tienda['INV_BUFFER'][i])    \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''''\n",
    "df_producto_tienda['Incremento_buffer'] = sigmoid(df_producto_tienda)\n",
    "#df_producto_tienda['Incremento_buffer'] = df_producto_tienda.apply(sigmoid, axis=1)\n",
    "df_producto_tienda['DB_Profundidad'] = df_producto_tienda['Nuevo_Buffer']*(1+df_producto_tienda['Incremento_buffer'])\n",
    "df_producto_tienda['DB_Profundidad'] = df_producto_tienda['DB_Profundidad'].round(0)\n",
    "\n",
    "#FORMATO\n",
    "#CHANGE DE FORMAT OF COLUMNS 'INV_BUFFER' AND 'INCREMENTO_BUFFER' TO PERCENTAGE\n",
    "df_producto_tienda['INV_BUFFER'] = df_producto_tienda['INV_BUFFER'].astype(str) + '%'\n",
    "df_producto_tienda['Incremento_buffer'] = df_producto_tienda['Incremento_buffer'].astype(str) + '%'\n",
    "\n",
    "#round by with the function rounby the values in the column 'DB_Profundidad'\n",
    "df_producto_tienda[\"DB_Profundidad\"] = df_producto_tienda.apply(lambda x: roundBy(x[\"DB_Profundidad\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_producto_tienda['INV_BUFFER_RNN'] = round(df_producto_tienda['Inventario_Actual'] / df_producto_tienda['Nuevo_Buffer_RNN']*100,1)\n",
    "df_producto_tienda['Nota_Buffer_RNN'] = df_producto_tienda['INV_BUFFER_RNN'].apply(condiciones)\n",
    "df_producto_tienda['Incremento_buffer_RNN'] = df_producto_tienda.apply(sigmoid, axis=1)\n",
    "df_producto_tienda['DB_Profundidad_RNN'] = df_producto_tienda['Nuevo_Buffer_RNN']*(1+df_producto_tienda['Incremento_buffer'])\n",
    "df_producto_tienda['DB_Profundidad_RNN'] = df_producto_tienda['DB_Profundidad_RNN'].round(0)\n",
    "\n",
    "#FORMATO\n",
    "#CHANGE DE FORMAT OF COLUMNS 'INV_BUFFER' AND 'INCREMENTO_BUFFER' TO PERCENTAGE\n",
    "df_producto_tienda['INV_BUFFER_RNN'] = df_producto_tienda['INV_BUFFER_RNN'].astype(str) + '%'\n",
    "df_producto_tienda['Incremento_buffer_RNN'] = df_producto_tienda['Incremento_buffer_RNN'].astype(str) + '%'\n",
    "\n",
    "#round by with the function rounby the values in the column 'DB_Profundidad'\n",
    "df_producto_tienda[\"DB_Profundidad_RNN\"] = df_producto_tienda.apply(lambda x: roundBy(x[\"DB_Profundidad\"],x[\"Multiplo_Distribucion\"], x[\"Multiplo_Distribucion\"]), axis=1)\n",
    "\n",
    "'''\n",
    "df_producto_tienda.to_excel(os.path.join(carpeta_output, 'BufferBasico_'+BU+'.xlsx'), index=False)\n",
    "\n",
    "buffer_dinamico = df_producto_tienda[['SKU','DB_Profundidad']].groupby('SKU').sum().reset_index()\n",
    "resumen = pd.merge(resumen, buffer_dinamico, on='SKU', how='left')\n",
    "resumen.to_excel(os.path.join(carpeta_output, 'Resumen_'+BU+'.xlsx'), index=False)\n",
    "\n",
    "\n",
    "print('Archivo de buffers por tiendas y resumen generados con exito en la carpeta de output', carpeta_output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d8efc0accedf8a71318180958b2a2c3ace073b5a0267b0b56f49dfe74d51c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
